# GENESIS Tasks ë””ë ‰í† ë¦¬

ì´ ë””ë ‰í† ë¦¬ëŠ” GENESIS ì‹¤í—˜ taskë“¤ì„ ê´€ë¦¬í•˜ëŠ” ê³³ì…ë‹ˆë‹¤. ê° taskëŠ” ë…ë¦½ì ì¸ ì‹¤í—˜ í™˜ê²½ìœ¼ë¡œ ì„¤ì •, ë¡œê·¸, ì²´í¬í¬ì¸íŠ¸ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

---

## ğŸ“‹ ëª©ì°¨

- [ë¹ ë¥¸ ì‹œì‘](#ë¹ ë¥¸-ì‹œì‘)
- [Task ìƒì„±](#task-ìƒì„±)
- [ì‹¤í–‰ ë°©ë²•](#ì‹¤í–‰-ë°©ë²•)
- [ëª¨ë‹ˆí„°ë§](#ëª¨ë‹ˆí„°ë§)
- [Task êµ¬ì¡°](#task-êµ¬ì¡°)
- [ìœ ìš©í•œ ëª…ë ¹ì–´](#ìœ ìš©í•œ-ëª…ë ¹ì–´)

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ìƒˆë¡œìš´ Task ìƒì„±

```bash
# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ìƒì„±
python3 create_task.py my_experiment

# íŠ¹ì • ì„¤ì •ìœ¼ë¡œ ìƒì„±
python3 create_task.py my_experiment --config testing
python3 create_task.py my_experiment --config cosine
```

### 2. ì‹¤í–‰

**Foreground (ë¡œì»¬ í…ŒìŠ¤íŠ¸):**
```bash
cd my_experiment
./run.sh
```

**Background (ì„œë²„ í•™ìŠµ):**
```bash
cd my_experiment
./start.sh           # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
./monitor.sh         # ìƒíƒœ í™•ì¸
./stop.sh            # ì¤‘ë‹¨
```

---

## ğŸ“ Task ìƒì„±

### ê¸°ë³¸ ì‚¬ìš©ë²•

```bash
python3 create_task.py <task_name> [--config CONFIG]
```

### ì˜ˆì‹œ

```bash
# ê¸°ë³¸ ì„¤ì • (default.yaml)
python3 create_task.py experiment_01

# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© (testing.yaml - 10% ë°ì´í„°)
python3 create_task.py quick_test --config testing

# Cosine annealing ìŠ¤ì¼€ì¤„ëŸ¬
python3 create_task.py cosine_exp --config cosine

# C-DiT ëª¨ë¸
python3 create_task.py c_dit_test --config models/c-dit
```

### ì‚¬ìš© ê°€ëŠ¥í•œ Config í…œí”Œë¦¿

```bash
# ê¸°ë³¸ ì„¤ì •
- default.yaml          # í‘œì¤€ ì„¤ì •
- testing.yaml          # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (10% ë°ì´í„°)
- cosine.yaml           # Cosine annealing ìŠ¤ì¼€ì¤„ëŸ¬

# ëª¨ë¸ë³„ ì„¤ì •
- models/c-dit.yaml     # Classifier-Attention DiT
- models/small_model.yaml  # ì‘ì€ ëª¨ë¸ (ë¹ ë¥¸ ì‹¤í—˜)

# í•™ìŠµ ì„¤ì •
- training/plateau.yaml      # ReduceLROnPlateau
- training/cosine_annealing.yaml  # Cosine annealing
- training/step.yaml         # Step LR
- training/linear.yaml       # Linear LR

# ë°ì´í„° ë³€í™˜
- data/ln_transform.yaml     # ln(1+x) ë³€í™˜
- data/log10_transform.yaml  # log10(1+x) ë³€í™˜
```

---

## ğŸ–¥ï¸ ì‹¤í–‰ ë°©ë²•

### Foreground ì‹¤í–‰ (ë¡œì»¬)

í™”ë©´ì—ì„œ ì§ì ‘ í™•ì¸í•˜ë©° ì‹¤í–‰:

```bash
cd my_experiment
./run.sh
```

**íŠ¹ì§•:**
- ì‹¤ì‹œê°„ ì¶œë ¥ í™•ì¸
- Ctrl+Cë¡œ ì¤‘ë‹¨
- í„°ë¯¸ë„ ì¢…ë£Œ ì‹œ í•™ìŠµë„ ì¤‘ë‹¨

**ì‚¬ìš© ì‹œê¸°:**
- ë¡œì»¬ ë¨¸ì‹ ì—ì„œ í…ŒìŠ¤íŠ¸
- ì„¤ì • í™•ì¸
- ë””ë²„ê¹…

---

### Background ì‹¤í–‰ (ì„œë²„)

nohupìœ¼ë¡œ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰:

```bash
cd my_experiment
./start.sh
```

**íŠ¹ì§•:**
- SSH ì—°ê²° ëŠì–´ë„ ê³„ì† ì‹¤í–‰
- PID íŒŒì¼ë¡œ í”„ë¡œì„¸ìŠ¤ ì¶”ì 
- ì¤‘ë³µ ì‹¤í–‰ ìë™ ë°©ì§€

**ì¶œë ¥:**
```
ğŸš€ Starting GENESIS training in background...
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Training started successfully!

ğŸ“Š Job Information:
   PID: 12345
   Task: my_experiment
   Time: 2024-01-14 02:54:30

ğŸ“ Log files:
   Console output: nohup.out
   Training log: logs/*_training.txt

ğŸ’¡ Monitoring commands:
   ./monitor.sh              # Show status
   ./stop.sh                 # Stop training
   tail -f nohup.out         # Watch console output
   tail -f logs/*_training.txt  # Watch training log
```

**ì‚¬ìš© ì‹œê¸°:**
- ì„œë²„ì—ì„œ ì¥ì‹œê°„ í•™ìŠµ
- ì—¬ëŸ¬ ì‹¤í—˜ ë™ì‹œ ì‹¤í–‰
- ì•ˆì •ì ì¸ í•™ìŠµ í™˜ê²½

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### `monitor.sh` - í†µí•© ëª¨ë‹ˆí„°ë§

ì „ì²´ ìƒíƒœë¥¼ í•œëˆˆì— í™•ì¸:

```bash
./monitor.sh
```

**í‘œì‹œ ì •ë³´:**
- âœ… í”„ë¡œì„¸ìŠ¤ ìƒíƒœ (RUNNING/NOT RUNNING)
- ğŸ“Š CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
- ğŸ–¥ï¸ GPU ì‚¬ìš© í˜„í™© (nvidia-smi)
- â±ï¸ ì‹¤í–‰ ì‹œê°„
- ğŸ“ ìµœê·¼ ë¡œê·¸ (Epoch/Loss)

**ì¶œë ¥ ì˜ˆì‹œ:**
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š GENESIS Training Status
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… Status: RUNNING

ğŸ“Š Process Information:
   PID: 12345
   CPU: 95.2%
   Memory: 8.4%
   Runtime: 01:23:45
   Command: python3 ../../scripts/train.py --config config.yaml

ğŸ–¥ï¸  GPU Usage:
   GPU 0: NVIDIA A100
   Utilization: 98%
   Memory: 18432 MB / 40960 MB

ğŸ“ Recent Log Output:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Epoch 10/100 Summary
Train Loss: 0.012345
Val Loss: 0.011234
Learning Rate: 0.0001
```

### ìë™ ê°±ì‹  ëª¨ë‹ˆí„°ë§

5ì´ˆë§ˆë‹¤ ìë™ìœ¼ë¡œ ìƒíƒœ í™•ì¸:

```bash
watch -n 5 ./monitor.sh
```

1ì´ˆë§ˆë‹¤ ë¹ ë¥¸ ê°±ì‹ :

```bash
watch -n 1 ./monitor.sh
```

### ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸

**ì½˜ì†” ì¶œë ¥ (ëª¨ë“  ì¶œë ¥):**
```bash
tail -f nohup.out
```

**í•™ìŠµ ë¡œê·¸ (í¬ë§·ëœ ì¶œë ¥):**
```bash
tail -f logs/*_training.txt
```

**íŠ¹ì • ì •ë³´ë§Œ í•„í„°ë§:**
```bash
# Epoch ì •ë³´ë§Œ
tail -f logs/*_training.txt | grep "Epoch"

# Loss ì •ë³´ë§Œ
tail -f logs/*_training.txt | grep "Loss"

# ì—ëŸ¬ë§Œ
tail -f nohup.out | grep -i "error"
```

---

## ğŸ›‘ í•™ìŠµ ì¤‘ë‹¨

### Graceful Shutdown

ì •ìƒì ìœ¼ë¡œ í•™ìŠµì„ ì¤‘ë‹¨í•˜ê³  ëª¨ë¸ì„ ì €ì¥:

```bash
./stop.sh
```

**ë™ì‘:**
1. SIGTERM ì‹ í˜¸ ì „ì†¡ (ì •ìƒ ì¢…ë£Œ)
2. 10ì´ˆ ëŒ€ê¸° (ëª¨ë¸ ì €ì¥ ì‹œê°„)
3. í•„ìš”ì‹œ SIGKILL (ê°•ì œ ì¢…ë£Œ)
4. `.pid` íŒŒì¼ ì •ë¦¬

**ì¶œë ¥:**
```
ğŸ›‘ Stopping GENESIS training...
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Found running process: PID 12345

Sending SIGTERM (graceful shutdown)...
..........
âœ… Process stopped gracefully
```

---

## ğŸ“‚ Task êµ¬ì¡°

ê° taskëŠ” ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤:

```
my_experiment/
â”œâ”€â”€ .pid                    # í”„ë¡œì„¸ìŠ¤ ID (ì‹¤í–‰ ì¤‘ì—ë§Œ ì¡´ì¬)
â”œâ”€â”€ nohup.out              # ì½˜ì†” ì¶œë ¥ (stderr + stdout)
â”œâ”€â”€ config.yaml            # ì‹¤í—˜ ì„¤ì •
â”œâ”€â”€ README.md              # Task ì„¤ëª…ì„œ
â”‚
â”œâ”€â”€ run.sh                 # ì¼ë°˜ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ start.sh               # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ monitor.sh             # ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ stop.sh                # ì¤‘ë‹¨ ìŠ¤í¬ë¦½íŠ¸
â”‚
â”œâ”€â”€ logs/                  # í•™ìŠµ ë¡œê·¸
â”‚   â””â”€â”€ icecube_diffusion_*_training.txt
â”‚
â””â”€â”€ outputs/               # í•™ìŠµ ê²°ê³¼
    â”œâ”€â”€ checkpoints/       # ì €ì¥ëœ ëª¨ë¸
    â”‚   â”œâ”€â”€ best_model.pth
    â”‚   â””â”€â”€ checkpoint_epoch_*.pth
    â”œâ”€â”€ samples/           # ìƒì„±ëœ ìƒ˜í”Œ
    â”œâ”€â”€ evaluation/        # í‰ê°€ ê²°ê³¼
    â”‚   â””â”€â”€ final_evaluation/
    â””â”€â”€ plots/             # ìƒì„±ëœ ê·¸ë˜í”„
        â”œâ”€â”€ training_curves.png    # í•™ìŠµ ê³¡ì„  (PNG)
        â””â”€â”€ training_curves.pdf    # í•™ìŠµ ê³¡ì„  (PDF)
```

---

## ğŸ”§ ìœ ìš©í•œ ëª…ë ¹ì–´

### í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬

```bash
# PID í™•ì¸
cat .pid

# í”„ë¡œì„¸ìŠ¤ ìƒì„¸ ì •ë³´
ps -p $(cat .pid) -f

# í”„ë¡œì„¸ìŠ¤ íŠ¸ë¦¬
pstree -p $(cat .pid)

# í”„ë¡œì„¸ìŠ¤ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
ps -p $(cat .pid) > /dev/null 2>&1 && echo "Running" || echo "Not running"

# ì‹¤í–‰ ì‹œê°„ í™•ì¸
ps -p $(cat .pid) -o etime=

# CPU/ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
top -p $(cat .pid)
```

### GPU ëª¨ë‹ˆí„°ë§

```bash
# ì‹¤ì‹œê°„ GPU ì‚¬ìš©ë¥ 
watch -n 1 nvidia-smi

# íŠ¹ì • í”„ë¡œì„¸ìŠ¤ GPU ì‚¬ìš©
nvidia-smi | grep $(cat .pid)

# GPU ë©”ëª¨ë¦¬ë§Œ
nvidia-smi --query-gpu=memory.used,memory.total --format=csv

# GPU ì˜¨ë„
nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader

# ëª¨ë“  GPU í”„ë¡œì„¸ìŠ¤
nvidia-smi pmon
```

### ë¡œê·¸ ë¶„ì„

```bash
# ë¡œê·¸ íŒŒì¼ í¬ê¸°
du -h logs/*_training.txt nohup.out

# ì „ì²´ ë¼ì¸ ìˆ˜
wc -l logs/*_training.txt

# íŠ¹ì • ë‹¨ì–´ ê°œìˆ˜
grep -c "Epoch" logs/*_training.txt

# ìµœê·¼ 100ì¤„
tail -n 100 logs/*_training.txt

# ì—ëŸ¬ ê²€ìƒ‰
grep -i "error" logs/*_training.txt nohup.out

# Val Loss ì¶”ì´
grep "Val Loss:" logs/*_training.txt

# íŠ¹ì • Epoch ê²€ìƒ‰
grep "Epoch 50" logs/*_training.txt
```

### ë””ìŠ¤í¬ ê´€ë¦¬

```bash
# Task ì „ì²´ í¬ê¸°
du -sh .

# ê° ë””ë ‰í† ë¦¬ í¬ê¸°
du -sh */ | sort -rh

# í° íŒŒì¼ ì°¾ê¸°
find . -type f -size +100M -exec ls -lh {} \;

# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
df -h .

# ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ (7ì¼ ì´ìƒ)
find outputs/checkpoints/ -name "*.pth" -mtime +7 -delete

# ë¡œê·¸ ì••ì¶•
gzip logs/*.txt
```

### ì—¬ëŸ¬ Task ê´€ë¦¬

```bash
# ëª¨ë“  Task ëª©ë¡
ls -d */

# ì‹¤í–‰ ì¤‘ì¸ Task ì°¾ê¸°
for task in */; do
    if [ -f "$task/.pid" ]; then
        echo "Running: $task (PID: $(cat $task/.pid))"
    fi
done

# ëª¨ë“  Task ìƒíƒœ í™•ì¸
for task in */; do
    echo "=== $task ==="
    cd "$task"
    if [ -f "monitor.sh" ]; then
        ./monitor.sh
    fi
    cd ..
done

# ëª¨ë“  ì‹¤í–‰ ì¤‘ì¸ Task ì¤‘ë‹¨
for task in */; do
    if [ -f "$task/.pid" ]; then
        echo "Stopping $task..."
        cd "$task"
        ./stop.sh
        cd ..
    fi
done
```

---

## ğŸ’¡ íŒ & íŠ¸ë¦­

### 1. Config ë¯¸ë¦¬ë³´ê¸°

Task ìƒì„± ì „ì— ì„¤ì • í™•ì¸:

```bash
cat ../configs/default.yaml
cat ../configs/testing.yaml
```

### 2. Config ìˆ˜ì •

Task ìƒì„± í›„ ì„¤ì • ë³€ê²½:

```bash
cd my_experiment
vim config.yaml
```

ì£¼ìš” ìˆ˜ì • í•­ëª©:
- `data.batch_size`: ë°°ì¹˜ í¬ê¸°
- `training.num_epochs`: ì—í¬í¬ ìˆ˜
- `training.learning_rate`: í•™ìŠµë¥ 
- `model.hidden`: ëª¨ë¸ í¬ê¸°

### 3. ì›ê²© ëª¨ë‹ˆí„°ë§

SSHë¡œ ì›ê²©ì—ì„œ ìƒíƒœ í™•ì¸:

```bash
ssh user@server "cd ~/GENESIS/GENESIS/tasks/my_experiment && ./monitor.sh"
```

ìë™ ê°±ì‹ :

```bash
watch -n 10 "ssh user@server 'cd ~/GENESIS/GENESIS/tasks/my_experiment && ./monitor.sh'"
```

### 4. ì‹¤í—˜ ë…¸íŠ¸

ê° taskì˜ README.mdì— ì‹¤í—˜ ë…¸íŠ¸ ì‘ì„±:

```bash
cd my_experiment
vim README.md
```

ê¸°ë¡í•  ë‚´ìš©:
- ì‹¤í—˜ ëª©ì 
- ë³€ê²½í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°
- ì˜ˆìƒ ê²°ê³¼
- ì‹¤ì œ ê²°ê³¼
- ë¬¸ì œì  ë° í•´ê²° ë°©ë²•

### 5. ê²°ê³¼ ë¹„êµ

ì—¬ëŸ¬ ì‹¤í—˜ ê²°ê³¼ ë¹„êµ:

```bash
# Val Loss ë¹„êµ
grep "Val Loss:" */logs/*_training.txt | tail -n 1

# ìµœê³  ì„±ëŠ¥ ì°¾ê¸°
for task in */; do
    loss=$(grep "New best model" $task/logs/*_training.txt 2>/dev/null | tail -n 1 | grep -oP '\d+\.\d+' | head -1)
    if [ ! -z "$loss" ]; then
        echo "$task: $loss"
    fi
done | sort -t: -k2 -n
```

### 6. ìë™ ì¬ì‹œì‘

í•™ìŠµ ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œì‘ (ì£¼ì˜í•´ì„œ ì‚¬ìš©):

```bash
# auto_restart.sh
#!/bin/bash
cd my_experiment
while true; do
    ./start.sh
    wait $(cat .pid)
    echo "Training stopped. Restarting in 10 seconds..."
    sleep 10
done
```

---

## ğŸ†˜ ë¬¸ì œ í•´ê²°

### 1. Task ìƒì„± ì‹¤íŒ¨

**ì¦ìƒ:** "Task already exists" ì—ëŸ¬

**í•´ê²°:**
```bash
# ë‹¤ë¥¸ ì´ë¦„ ì‚¬ìš© ë˜ëŠ” ê¸°ì¡´ task ì‚­ì œ
rm -rf my_experiment
python3 create_task.py my_experiment
```

### 2. ì‹œì‘ ì‹¤íŒ¨

**ì¦ìƒ:** `./start.sh`ê°€ ì‹¤íŒ¨

**í™•ì¸:**
```bash
# ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸
cat nohup.out

# Python í™˜ê²½ í™•ì¸
which python3
python3 --version

# ë°ì´í„° ê²½ë¡œ í™•ì¸
grep h5_path config.yaml
```

### 3. PID íŒŒì¼ ë¬¸ì œ

**ì¦ìƒ:** "stale PID file" ê²½ê³ 

**í•´ê²°:**
```bash
# PID íŒŒì¼ ì‚­ì œ
rm .pid

# ë‹¤ì‹œ ì‹œì‘
./start.sh
```

### 4. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±

**ì¦ìƒ:** CUDA out of memory

**í•´ê²°:**
```bash
# 1. ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
vim config.yaml
# data.batch_size: 512 â†’ 256

# 2. ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ í™•ì¸ ë° ì¢…ë£Œ
nvidia-smi
kill <PID>

# 3. GPU ì¬ì‹œì‘ (ì£¼ì˜!)
sudo nvidia-smi --gpu-reset
```

### 5. ë””ìŠ¤í¬ ìš©ëŸ‰ ë¶€ì¡±

**í•´ê²°:**
```bash
# ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ
find outputs/checkpoints/ -name "checkpoint_epoch_*.pth" -mtime +7 -delete

# ë¡œê·¸ ì••ì¶•
gzip logs/*.txt nohup.out

# ë¶ˆí•„ìš”í•œ task ì‚­ì œ
rm -rf old_experiment
```

---

## ğŸ“š ì¶”ê°€ ë¬¸ì„œ

- **ì™„ë²½í•œ ê°€ì´ë“œ**: [docs/guides/NOHUP_MONITORING.md](../docs/guides/NOHUP_MONITORING.md)
- **Training Guide**: [docs/guides/TRAINING.md](../docs/guides/TRAINING.md)
- **Configuration Guide**: [docs/guides/NORMALIZATION_CONFIG.md](../docs/guides/NORMALIZATION_CONFIG.md)
- **GPU Optimization**: [gpu_tools/README.md](../gpu_tools/README.md)

---

## ğŸ“ ì˜ˆì‹œ ì›Œí¬í”Œë¡œìš°

### ì‹¤í—˜ ì‹œì‘ë¶€í„° ê²°ê³¼ í™•ì¸ê¹Œì§€

```bash
# 1. Task ìƒì„±
cd ~/GENESIS/GENESIS/tasks
python3 create_task.py experiment_20240114

# 2. ì„¤ì • í™•ì¸ ë° ìˆ˜ì • (í•„ìš”ì‹œ)
cd experiment_20240114
vim config.yaml

# 3. ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
./start.sh

# 4. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (ë³„ë„ í„°ë¯¸ë„)
watch -n 5 ./monitor.sh

# 5. ë¡œê·¸ í™•ì¸ (ë˜ ë‹¤ë¥¸ í„°ë¯¸ë„)
tail -f logs/*_training.txt

# 6. SSH ì ‘ì† ì¢…ë£Œ (í•™ìŠµì€ ê³„ì†ë¨)
exit

# --- ë‚˜ì¤‘ì— ë‹¤ì‹œ ì ‘ì† ---

# 7. ìƒíƒœ í™•ì¸
cd ~/GENESIS/GENESIS/tasks/experiment_20240114
./monitor.sh

# 8. ê²°ê³¼ í™•ì¸
cat logs/*_training.txt | grep "New best model"
ls outputs/checkpoints/

# 9. ìƒ˜í”Œë§ (í•™ìŠµ ì™„ë£Œ í›„)
python3 ../../scripts/sample.py --checkpoint outputs/checkpoints/best_model.pth

# 10. ì‹¤í—˜ ë…¸íŠ¸ ì‘ì„±
vim README.md
```

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2024-01-14  
**ë²„ì „**: 1.0
