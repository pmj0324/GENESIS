{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[demo] loss: 1.220773\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# PMT Diffusion Transformer (DiT-style) for 5160 PMTs\n",
    "# Inputs per PMT: [npe, time] + [xpmt, ypmt, zpmt]\n",
    "# Output: predicted noise for [npe, time]\n",
    "#\n",
    "# Model:\n",
    "#   - Signal MLP: (2)  -> (h)\n",
    "#   - Position MLP: (3) -> (h)\n",
    "#   - Sum to form token embeddings: (B, 5160, h)\n",
    "#   - DiT-style conditioning: timestep + condition (6-dim) via AdaLN-Zero in each block\n",
    "#   - Self-attention over 5160 tokens\n",
    "#   - Head: (h) -> (2) per token\n",
    "#\n",
    "# Notes:\n",
    "#   - Dataset expected to yield: {\"x\":[B,2,5160], \"pos\":[B,5160,3], \"c\":[B,6]}\n",
    "#   - Training step shows simple VP-style noising for demo.\n",
    "\n",
    "import math\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Optional, Dict\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Dataset (same contract as discussed)\n",
    "# ----------------------------\n",
    "def _np_stack3(x1, x2, x3):\n",
    "    import numpy as np\n",
    "    a = np.asarray(x1).reshape(-1)\n",
    "    b = np.asarray(x2).reshape(-1)\n",
    "    c = np.asarray(x3).reshape(-1)\n",
    "    return np.stack([a, b, c], axis=-1)  # (L,3)\n",
    "\n",
    "class PMTH5Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Event-wise loader for an HDF5 file with:\n",
    "      - /input:     (N, 2, 5160)    charge & time\n",
    "      - /label:     (N, 6)          (we will return it as condition 'c')\n",
    "      - /xpmt:      (5160,)\n",
    "      - /ypmt:      (5160,)\n",
    "      - /zpmt:      (5160,)\n",
    "    \"\"\"\n",
    "    def __init__(self, h5_path: str,\n",
    "                 input_key: str=\"input\", condition_key: str=\"label\",\n",
    "                 x_key: str=\"xpmt\", y_key: str=\"ypmt\", z_key: str=\"zpmt\",\n",
    "                 dtype: torch.dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        self.h5_path = h5_path\n",
    "        self.input_key = input_key\n",
    "        self.condition_key = condition_key\n",
    "        self.x_key = x_key\n",
    "        self.y_key = y_key\n",
    "        self.z_key = z_key\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self._h5: Optional[h5py.File] = None\n",
    "        self._input = None\n",
    "        self._cond  = None\n",
    "        self._xp    = None\n",
    "        self._yp    = None\n",
    "        self._zp    = None\n",
    "        self._length = None\n",
    "\n",
    "    def _ensure_open(self):\n",
    "        if self._h5 is None:\n",
    "            self._h5 = h5py.File(self.h5_path, \"r\")\n",
    "            self._input = self._h5[self.input_key]\n",
    "            self._cond  = self._h5[self.condition_key]\n",
    "            self._xp    = self._h5[self.x_key]\n",
    "            self._yp    = self._h5[self.y_key]\n",
    "            self._zp    = self._h5[self.z_key]\n",
    "            self._length = self._input.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        self._ensure_open()\n",
    "        return self._length\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        self._ensure_open()\n",
    "        x_np  = self._input[idx]                            # (2,5160)\n",
    "        c_np  = self._cond[idx]                             # (6,)\n",
    "        pos_np = _np_stack3(self._xp, self._yp, self._zp)   # (5160,3)\n",
    "\n",
    "        x   = torch.as_tensor(x_np, dtype=self.dtype)               # (2,5160)\n",
    "        pos = torch.as_tensor(pos_np, dtype=self.dtype)             # (5160,3)\n",
    "        c   = torch.as_tensor(c_np, dtype=self.dtype)               # (6,)\n",
    "        return {\"x\": x, \"pos\": pos, \"c\": c, \"idx\": idx}\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Utils: embeddings and AdaLN-Zero\n",
    "# ----------------------------\n",
    "def sinusoidal_timestep_embedding(t: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create sinusoidal timestep embeddings (as in Transformer pos-emb).\n",
    "    t: (B,) in [0, 1] or integer timesteps scaled.\n",
    "    Returns (B, dim)\n",
    "    \"\"\"\n",
    "    device = t.device\n",
    "    half = dim // 2\n",
    "    # Use log-scale frequencies.\n",
    "    freqs = torch.exp(\n",
    "        torch.linspace(\n",
    "            math.log(1.0), math.log(10000.0), steps=half, device=device\n",
    "        )\n",
    "    )\n",
    "    args = t[:, None] * freqs[None, :]\n",
    "    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "    if dim % 2 == 1:  # pad if odd\n",
    "        emb = torch.nn.functional.pad(emb, (0,1))\n",
    "    return emb  # (B, dim)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Simple 2-layer MLP with GELU.\"\"\"\n",
    "    def __init__(self, in_dim, hidden, out_dim, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, out_dim),\n",
    "        )\n",
    "    def forward(self, x):  # (..., in_dim) -> (..., out_dim)\n",
    "        return self.net(x)\n",
    "\n",
    "class AdaLNZero(nn.Module):\n",
    "    \"\"\"\n",
    "    AdaLN-Zero modulation block (as in DiT).\n",
    "    Given a normalized hidden h and conditioning vector m, produce:\n",
    "      mod(h) = h * (1 + gamma) + beta\n",
    "    where [gamma, beta] are predicted from m. Optionally use a residual gate.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim: int, cond_dim: int):\n",
    "        super().__init__()\n",
    "        self.ln = nn.LayerNorm(hidden_dim, elementwise_affine=False)\n",
    "        # Predict scale, shift, and residual gate from cond vector.\n",
    "        self.mod = nn.Linear(cond_dim, hidden_dim * 3)\n",
    "        # Initialize to zeros for \"Zero\" init (stabilizes early training).\n",
    "        nn.init.zeros_(self.mod.weight)\n",
    "        nn.init.zeros_(self.mod.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, cond_vec: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x: (B, L, H)\n",
    "        cond_vec: (B, cond_dim)\n",
    "        Returns:\n",
    "           x_mod: (B, L, H)\n",
    "           gate:  (B, 1, H) gate for residual path\n",
    "        \"\"\"\n",
    "        h = self.ln(x)\n",
    "        m = self.mod(cond_vec)  # (B, 3H)\n",
    "        gamma, beta, gate = torch.chunk(m, 3, dim=-1)  # (B,H) each\n",
    "        gamma = gamma.unsqueeze(1)\n",
    "        beta  = beta.unsqueeze(1)\n",
    "        gate  = gate.unsqueeze(1)\n",
    "        x_mod = h * (1 + gamma) + beta\n",
    "        return x_mod, gate\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Transformer Block with AdaLN\n",
    "# ----------------------------\n",
    "class DiTBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer block with AdaLN-Zero conditioning for both Attn and MLP paths.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim: int, n_heads: int, mlp_ratio: float=4.0, dropout: float=0.0, cond_dim: int=256):\n",
    "        super().__init__()\n",
    "        self.attn_mod = AdaLNZero(hidden_dim, cond_dim)\n",
    "        self.mlp_mod  = AdaLNZero(hidden_dim, cond_dim)\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=n_heads,\n",
    "                                          batch_first=True, dropout=dropout)\n",
    "        self.attn_drop = nn.Dropout(dropout)\n",
    "\n",
    "        mlp_hidden = int(hidden_dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, mlp_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_hidden, hidden_dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, cond_vec: torch.Tensor):\n",
    "        # Attention path\n",
    "        x_mod, gate_attn = self.attn_mod(x, cond_vec)     # (B,L,H), (B,1,H)\n",
    "        attn_out, _ = self.attn(x_mod, x_mod, x_mod, need_weights=False)\n",
    "        x = x + gate_attn * self.attn_drop(attn_out)\n",
    "\n",
    "        # MLP path\n",
    "        x_mod, gate_mlp = self.mlp_mod(x, cond_vec)\n",
    "        x = x + gate_mlp * self.mlp(x_mod)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# PMT DiT Model\n",
    "# ----------------------------\n",
    "class PMTDiT(nn.Module):\n",
    "    \"\"\"\n",
    "    PMT DiT-style transformer for diffusion noise prediction.\n",
    "    - signal_mlp: (npe,time)->h\n",
    "    - pos_mlp:    (xpmt,ypmt,zpmt)->h\n",
    "    - token = signal_emb + pos_emb\n",
    "    - K transformer blocks with AdaLN-Zero conditioned on (timestep + condition)\n",
    "    - head projects tokens to 2-dim noise per PMT\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 hidden_dim: int=256,\n",
    "                 depth: int=6,\n",
    "                 n_heads: int=8,\n",
    "                 cond_in_dim: int=6,      # condition vector dimension\n",
    "                 t_embed_dim: int=256,    # timestep embedding dimension\n",
    "                 cond_embed_dim: int=256, # condition embedding dimension\n",
    "                 dropout: float=0.0):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Embedding blocks\n",
    "        self.signal_mlp = MLP(in_dim=2, hidden=hidden_dim, out_dim=hidden_dim, dropout=dropout)\n",
    "        self.pos_mlp    = MLP(in_dim=3, hidden=hidden_dim, out_dim=hidden_dim, dropout=dropout)\n",
    "\n",
    "        # Timestep and condition embeddings\n",
    "        self.t_embed_dim = t_embed_dim\n",
    "        self.c_embed = MLP(in_dim=cond_in_dim, hidden=cond_embed_dim, out_dim=t_embed_dim, dropout=dropout)\n",
    "\n",
    "        # Fuse t and c -> global cond vector for blocks\n",
    "        self.fuse = MLP(in_dim=t_embed_dim, hidden=t_embed_dim, out_dim=t_embed_dim, dropout=dropout)\n",
    "\n",
    "        # Transformer blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            DiTBlock(hidden_dim=hidden_dim, n_heads=n_heads, mlp_ratio=4.0, dropout=dropout, cond_dim=t_embed_dim)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "\n",
    "        # Output head\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "        self.head = nn.Linear(hidden_dim, 2)  # predict noise for (npe, time)\n",
    "\n",
    "    def forward(self, x_sig: torch.Tensor, pos: torch.Tensor, c: torch.Tensor, t: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x_sig: (B, 2, 5160)          signal [npe, time]\n",
    "        pos:   (B, 5160, 3)          positions [x,y,z]\n",
    "        c:     (B, 6)                condition\n",
    "        t:     (B,)                  timestep in [0,1] (float) or scaled ints / T\n",
    "        Returns:\n",
    "          eps_pred: (B, 2, 5160)\n",
    "        \"\"\"\n",
    "        B = x_sig.shape[0]\n",
    "        # Prepare tokens: (B, 5160, h)\n",
    "        sig_tok = self.signal_mlp(x_sig.transpose(1, 2))  # (B,5160,2)->(B,5160,h)\n",
    "        pos_tok = self.pos_mlp(pos)                       # (B,5160,3)->(B,5160,h)\n",
    "        tok = sig_tok + pos_tok                           # (B,5160,h)\n",
    "\n",
    "        # Build DiT conditioning vector\n",
    "        t_emb = sinusoidal_timestep_embedding(t, self.t_embed_dim)  # (B, D)\n",
    "        c_emb = self.c_embed(c)                                     # (B, D)\n",
    "        cond_vec = self.fuse(t_emb + c_emb)                         # (B, D)\n",
    "\n",
    "        # Transformer\n",
    "        h = tok\n",
    "        for blk in self.blocks:\n",
    "            h = blk(h, cond_vec)                                    # (B,5160,h)\n",
    "\n",
    "        h = self.norm(h)\n",
    "        eps = self.head(h)            # (B,5160,2)\n",
    "        return eps.transpose(1, 2)    # (B,2,5160)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Simple training step (demo)\n",
    "# ----------------------------\n",
    "@torch.no_grad()\n",
    "def vp_noising(x0: torch.Tensor, t: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Simple VP-style noising: x_t = sqrt(1 - t) * x0 + sqrt(t) * eps\n",
    "    x0: (B,2,5160), t: (B,) in [0,1]\n",
    "    Returns: x_t, eps\n",
    "    \"\"\"\n",
    "    B = x0.shape[0]\n",
    "    eps = torch.randn_like(x0)\n",
    "    t = t.view(B, 1, 1)\n",
    "    x_t = torch.sqrt(1.0 - t) * x0 + torch.sqrt(t) * eps\n",
    "    return x_t, eps\n",
    "\n",
    "def training_step(model: PMTDiT, batch: Dict[str, torch.Tensor], optimizer, device):\n",
    "    \"\"\"\n",
    "    One training step:\n",
    "      - Sample t ~ U(0,1)\n",
    "      - Make x_t and eps\n",
    "      - Predict eps and compute MSE\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    x0  = batch[\"x\"].to(device)        # (B,2,5160)\n",
    "    pos = batch[\"pos\"].to(device)      # (B,5160,3)\n",
    "    c   = batch[\"c\"].to(device)        # (B,6)\n",
    "    B   = x0.shape[0]\n",
    "    t   = torch.rand(B, device=device) # (B,)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x_t, eps = vp_noising(x0, t)\n",
    "\n",
    "    eps_pred = model(x_sig=x_t, pos=pos, c=c, t=t)  # (B,2,5160)\n",
    "\n",
    "    loss = torch.mean((eps_pred - eps) ** 2)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Minimal usage example\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Adjust paths and hyperparams as needed.\n",
    "    h5_path = \"/home/work/GENESIS/GENESIS-data/22644_0921.h5\"\n",
    "    batch_size = 2\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    ds = PMTH5Dataset(h5_path=h5_path)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    model = PMTDiT(hidden_dim=256, depth=4, n_heads=8, cond_in_dim=6, t_embed_dim=256, cond_embed_dim=256, dropout=0.0).to(device)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "    # One demo step\n",
    "    batch = next(iter(loader))\n",
    "    loss = training_step(model, batch, optim, device)\n",
    "    print(f\"[demo] loss: {loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -p PATH [--batch-size BATCH_SIZE]\n",
      "                             [--hidden-dim HIDDEN_DIM] [--depth DEPTH]\n",
      "                             [--heads HEADS] [--dropout DROPOUT]\n",
      "                             [--schedule {linear,cosine}] [--T T] [--lr LR]\n",
      "                             [--steps STEPS] [--workers WORKERS]\n",
      "ipykernel_launcher.py: error: the following arguments are required: -p/--path\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# PMT Diffusion Transformer (DiT-style) for 5160 PMTs with DDPM q-sample\n",
    "# Inputs per PMT: [npe, time] + [xpmt, ypmt, zpmt]\n",
    "# Output: predicted noise for [npe, time]\n",
    "#\n",
    "# Dataset yields:\n",
    "#   x:   (B, 2, 5160)     # [npe, time]\n",
    "#   pos: (B, 5160, 3)     # [xpmt, ypmt, zpmt]\n",
    "#   c:   (B, 6)           # condition vector (from '/label')\n",
    "#\n",
    "# Model:\n",
    "#   - Signal MLP:   (2)  -> (h)\n",
    "#   - Position MLP: (3)  -> (h)\n",
    "#   - Token = signal_emb + pos_emb  => (B, 5160, h)\n",
    "#   - K DiT-style transformer blocks with AdaLN-Zero conditioning\n",
    "#   - Head: (h) -> (2) per token   => (B, 2, 5160)\n",
    "#\n",
    "# Training:\n",
    "#   - DDPM q-sample with linear or cosine beta schedule\n",
    "#   - t_int ~ Unif{0..T-1}, x_t = sqrt(alpha_bar[t])*x0 + sqrt(1-alpha_bar[t])*eps\n",
    "#   - Model predicts eps, MSE loss\n",
    "\n",
    "import math\n",
    "from typing import Optional, Dict\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Dataset\n",
    "# ----------------------------\n",
    "def _np_stack3(x1, x2, x3):\n",
    "    \"\"\"Stack 1D arrays into shape (L, 3).\"\"\"\n",
    "    a = np.asarray(x1).reshape(-1)\n",
    "    b = np.asarray(x2).reshape(-1)\n",
    "    c = np.asarray(x3).reshape(-1)\n",
    "    return np.stack([a, b, c], axis=-1)  # (L,3)\n",
    "\n",
    "class PMTH5Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Event-wise loader for an HDF5 file with:\n",
    "      - /input: (N, 2, 5160)   charge & time\n",
    "      - /label: (N, 6)         condition vector (returned as 'c')\n",
    "      - /xpmt, /ypmt, /zpmt: (5160,) PMT positions\n",
    "    \"\"\"\n",
    "    def __init__(self, h5_path: str,\n",
    "                 input_key: str = \"input\",\n",
    "                 condition_key: str = \"label\",  # read 'label' but return as 'c'\n",
    "                 x_key: str = \"xpmt\",\n",
    "                 y_key: str = \"ypmt\",\n",
    "                 z_key: str = \"zpmt\",\n",
    "                 dtype: torch.dtype = torch.float32):\n",
    "        super().__init__()\n",
    "        self.h5_path = h5_path\n",
    "        self.input_key = input_key\n",
    "        self.condition_key = condition_key\n",
    "        self.x_key = x_key\n",
    "        self.y_key = y_key\n",
    "        self.z_key = z_key\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self._h5: Optional[h5py.File] = None\n",
    "        self._input = None\n",
    "        self._cond = None\n",
    "        self._xp = None\n",
    "        self._yp = None\n",
    "        self._zp = None\n",
    "        self._length = None\n",
    "        self._pos_cache: Optional[torch.Tensor] = None  # cached (5160,3) on CPU\n",
    "\n",
    "    def _ensure_open(self):\n",
    "        \"\"\"Lazy-open HDF5 file (safe with DataLoader workers).\"\"\"\n",
    "        if self._h5 is None:\n",
    "            self._h5 = h5py.File(self.h5_path, \"r\")\n",
    "            self._input = self._h5[self.input_key]\n",
    "            self._cond  = self._h5[self.condition_key]\n",
    "            self._xp    = self._h5[self.x_key]\n",
    "            self._yp    = self._h5[self.y_key]\n",
    "            self._zp    = self._h5[self.z_key]\n",
    "            self._length = self._input.shape[0]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        self._ensure_open()\n",
    "        return self._length\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        self._ensure_open()\n",
    "        x_np  = self._input[idx]                            # (2,5160)\n",
    "        c_np  = self._cond[idx]                             # (6,)\n",
    "\n",
    "        # Cache shared positions once (as CPU tensor)\n",
    "        if self._pos_cache is None:\n",
    "            pos_np = _np_stack3(self._xp, self._yp, self._zp)  # (5160,3)\n",
    "            self._pos_cache = torch.as_tensor(pos_np, dtype=self.dtype)\n",
    "\n",
    "        x   = torch.as_tensor(x_np, dtype=self.dtype)            # (2,5160)\n",
    "        pos = self._pos_cache                                    # (5160,3) shared\n",
    "        c   = torch.as_tensor(c_np, dtype=self.dtype)            # (6,)\n",
    "        return {\"x\": x, \"pos\": pos, \"c\": c, \"idx\": idx}\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close file handle manually if needed.\"\"\"\n",
    "        if self._h5 is not None:\n",
    "            try:\n",
    "                self._h5.close()\n",
    "            finally:\n",
    "                self._h5 = None\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Embeddings, AdaLN-Zero\n",
    "# ----------------------------\n",
    "def sinusoidal_timestep_embedding(t: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Sinusoidal embedding for scalar timesteps in [0,1] or scaled ints.\n",
    "    t: (B,)\n",
    "    returns: (B, dim)\n",
    "    \"\"\"\n",
    "    device = t.device\n",
    "    half = dim // 2\n",
    "    # Log-scale frequencies for stability\n",
    "    freqs = torch.exp(torch.linspace(math.log(1.0), math.log(10000.0), steps=half, device=device))\n",
    "    args = t[:, None] * freqs[None, :]\n",
    "    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "    if dim % 2 == 1:\n",
    "        emb = torch.nn.functional.pad(emb, (0, 1))\n",
    "    return emb\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Two-layer MLP with GELU and optional dropout.\"\"\"\n",
    "    def __init__(self, in_dim, hidden, out_dim, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, out_dim),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class AdaLNZero(nn.Module):\n",
    "    \"\"\"\n",
    "    AdaLN-Zero: layer-norm then FiLM-like mod with zero-initialized scale/shift/gate.\n",
    "    Given x (B,L,H) and cond_vec (B,C), predict gamma,beta,gate in (B,H) then:\n",
    "      y = LN(x) * (1+gamma) + beta\n",
    "      out = x + gate * F(y)\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim: int, cond_dim: int):\n",
    "        super().__init__()\n",
    "        self.ln = nn.LayerNorm(hidden_dim, elementwise_affine=False)\n",
    "        self.mod = nn.Linear(cond_dim, hidden_dim * 3)\n",
    "        nn.init.zeros_(self.mod.weight)\n",
    "        nn.init.zeros_(self.mod.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, cond_vec: torch.Tensor):\n",
    "        h = self.ln(x)                        # (B,L,H)\n",
    "        m = self.mod(cond_vec)                # (B,3H)\n",
    "        gamma, beta, gate = torch.chunk(m, 3, dim=-1)  # (B,H) each\n",
    "        gamma = gamma.unsqueeze(1)            # (B,1,H)\n",
    "        beta  = beta.unsqueeze(1)\n",
    "        gate  = gate.unsqueeze(1)\n",
    "        y = h * (1 + gamma) + beta\n",
    "        return y, gate\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Transformer Block (DiT-style)\n",
    "# ----------------------------\n",
    "class DiTBlock(nn.Module):\n",
    "    \"\"\"Transformer block with AdaLN-Zero conditioning on both Attn and MLP paths.\"\"\"\n",
    "    def __init__(self, hidden_dim: int, n_heads: int, mlp_ratio: float = 4.0, dropout: float = 0.0, cond_dim: int = 256):\n",
    "        super().__init__()\n",
    "        self.attn_mod = AdaLNZero(hidden_dim, cond_dim)\n",
    "        self.mlp_mod  = AdaLNZero(hidden_dim, cond_dim)\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=n_heads,\n",
    "                                          batch_first=True, dropout=dropout)\n",
    "        self.attn_drop = nn.Dropout(dropout)\n",
    "\n",
    "        mlp_hidden = int(hidden_dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, mlp_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_hidden, hidden_dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, cond_vec: torch.Tensor):\n",
    "        # Attention path\n",
    "        x_mod, gate_attn = self.attn_mod(x, cond_vec)\n",
    "        attn_out, _ = self.attn(x_mod, x_mod, x_mod, need_weights=False)  # (B,L,H)\n",
    "        x = x + gate_attn * self.attn_drop(attn_out)\n",
    "\n",
    "        # MLP path\n",
    "        x_mod, gate_mlp = self.mlp_mod(x, cond_vec)\n",
    "        x = x + gate_mlp * self.mlp(x_mod)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# PMT DiT Model\n",
    "# ----------------------------\n",
    "class PMTDiT(nn.Module):\n",
    "    \"\"\"\n",
    "    DiT-style transformer conditioned on timestep + condition vector.\n",
    "    - signal_mlp: (npe,time)->h\n",
    "    - pos_mlp:    (x,y,z)->h\n",
    "    - token = signal_emb + pos_emb\n",
    "    - blocks: DiT blocks with AdaLN-Zero\n",
    "    - head: predict eps for (npe,time)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 hidden_dim: int = 256,\n",
    "                 depth: int = 6,\n",
    "                 n_heads: int = 8,\n",
    "                 cond_in_dim: int = 6,\n",
    "                 t_embed_dim: int = 256,\n",
    "                 cond_embed_dim: int = 256,\n",
    "                 dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Embeddings\n",
    "        self.signal_mlp = MLP(in_dim=2, hidden=hidden_dim, out_dim=hidden_dim, dropout=dropout)\n",
    "        self.pos_mlp    = MLP(in_dim=3, hidden=hidden_dim, out_dim=hidden_dim, dropout=dropout)\n",
    "\n",
    "        # Timestep & condition embeddings\n",
    "        self.t_embed_dim = t_embed_dim\n",
    "        self.c_embed = MLP(in_dim=cond_in_dim, hidden=cond_embed_dim, out_dim=t_embed_dim, dropout=dropout)\n",
    "        self.fuse = MLP(in_dim=t_embed_dim, hidden=t_embed_dim, out_dim=t_embed_dim, dropout=dropout)  # fuse t+c\n",
    "\n",
    "        # Transformer blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            DiTBlock(hidden_dim=hidden_dim, n_heads=n_heads, mlp_ratio=4.0, dropout=dropout, cond_dim=t_embed_dim)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "\n",
    "        # Head\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "        self.head = nn.Linear(hidden_dim, 2)  # predict eps for (npe,time)\n",
    "\n",
    "    def forward(self, x_sig: torch.Tensor, pos: torch.Tensor, c: torch.Tensor, t_float01: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x_sig:     (B, 2, 5160)\n",
    "        pos:       (B, 5160, 3)\n",
    "        c:         (B, 6)\n",
    "        t_float01: (B,) float in [0,1] for time embedding\n",
    "        returns:   eps_pred (B, 2, 5160)\n",
    "        \"\"\"\n",
    "        # Tokenize\n",
    "        sig_tok = self.signal_mlp(x_sig.transpose(1, 2))  # (B,5160,2)->(B,5160,h)\n",
    "        pos_tok = self.pos_mlp(pos)                       # (B,5160,3)->(B,5160,h)\n",
    "        tok = sig_tok + pos_tok                           # (B,5160,h)\n",
    "\n",
    "        # DiT conditioning vector\n",
    "        t_emb = sinusoidal_timestep_embedding(t_float01, self.t_embed_dim)  # (B,D)\n",
    "        c_emb = self.c_embed(c)                                             # (B,D)\n",
    "        cond_vec = self.fuse(t_emb + c_emb)                                 # (B,D)\n",
    "\n",
    "        # Transformer\n",
    "        h = tok\n",
    "        for blk in self.blocks:\n",
    "            h = blk(h, cond_vec)                                            # (B,5160,h)\n",
    "\n",
    "        h = self.norm(h)\n",
    "        eps = self.head(h)             # (B,5160,2)\n",
    "        return eps.transpose(1, 2)     # (B,2,5160)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# DDPM schedules and q-sample\n",
    "# ----------------------------\n",
    "def make_beta_schedule_linear(T: int, start: float = 1e-4, end: float = 2e-2):\n",
    "    \"\"\"Linear beta schedule in [start, end].\"\"\"\n",
    "    betas = torch.linspace(start, end, T, dtype=torch.float32)\n",
    "    alphas = 1.0 - betas\n",
    "    alpha_bars = torch.cumprod(alphas, dim=0)  # (T,)\n",
    "    return betas, alphas, alpha_bars\n",
    "\n",
    "def make_beta_schedule_cosine(T: int, s: float = 0.008):\n",
    "    \"\"\"\n",
    "    Cosine schedule (Nichol & Dhariwal, 2021):\n",
    "      alpha_bar(t) = cos^2( (t/T + s)/(1+s) * pi/2 )\n",
    "    Convert to discrete betas via alpha_bar ratio.\n",
    "    \"\"\"\n",
    "    steps = torch.arange(T + 1, dtype=torch.float64)\n",
    "    f = torch.cos(((steps / T) + s) / (1 + s) * math.pi / 2) ** 2  # (T+1,)\n",
    "    f = f / f[0]  # normalize so alpha_bar(0)=1\n",
    "    # beta_t = 1 - alpha_bar(t+1)/alpha_bar(t)\n",
    "    betas = (1 - (f[1:] / f[:-1]).clamp(min=1e-12)).to(torch.float32)\n",
    "    betas = betas.clamp(min=1e-8, max=0.999)\n",
    "    alphas = 1.0 - betas\n",
    "    alpha_bars = torch.cumprod(alphas, dim=0).to(torch.float32)\n",
    "    return betas, alphas, alpha_bars\n",
    "\n",
    "def q_sample(x0: torch.Tensor, t_int: torch.Tensor, alpha_bars: torch.Tensor):\n",
    "    \"\"\"\n",
    "    DDPM forward noising:\n",
    "      x_t = sqrt(alpha_bar[t]) * x0 + sqrt(1 - alpha_bar[t]) * eps\n",
    "    x0:      (B, 2, 5160)\n",
    "    t_int:   (B,) integer in [0, T-1]\n",
    "    returns: x_t, eps\n",
    "    \"\"\"\n",
    "    B = x0.shape[0]\n",
    "    eps = torch.randn_like(x0)\n",
    "    ab = alpha_bars.to(x0.device)[t_int].view(B, 1, 1)  # (B,1,1)\n",
    "    x_t = torch.sqrt(ab) * x0 + torch.sqrt(1.0 - ab) * eps\n",
    "    return x_t, eps\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Training step\n",
    "# ----------------------------\n",
    "def training_step_ddpm(model: PMTDiT, batch: Dict[str, torch.Tensor], optimizer, device,\n",
    "                       alpha_bars: torch.Tensor, T: int):\n",
    "    \"\"\"\n",
    "    One DDPM training step:\n",
    "      - sample t_int in [0, T-1]\n",
    "      - q_sample to get (x_t, eps)\n",
    "      - predict eps and compute MSE\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    x0  = batch[\"x\"].to(device)     # (B,2,5160)\n",
    "    pos = batch[\"pos\"].to(device)   # (B,5160,3)\n",
    "    c   = batch[\"c\"].to(device)     # (B,6)\n",
    "    B   = x0.shape[0]\n",
    "\n",
    "    t_int = torch.randint(0, T, (B,), device=device)          # (B,)\n",
    "    x_t, eps = q_sample(x0, t_int, alpha_bars)\n",
    "\n",
    "    # Normalized timestep [0,1] for embedding\n",
    "    t_norm = t_int.float() / (T - 1)\n",
    "\n",
    "    eps_pred = model(x_sig=x_t, pos=pos, c=c, t_float01=t_norm)  # (B,2,5160)\n",
    "    loss = torch.mean((eps_pred - eps) ** 2)\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Minimal runnable demo\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    import os\n",
    "\n",
    "    # --- CLI ---\n",
    "    parser = argparse.ArgumentParser(description=\"PMT DiT diffusion demo (DDPM q-sample).\")\n",
    "    parser.add_argument(\"-p\", \"--path\", required=True, help=\"Path to HDF5 file\")\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=4)\n",
    "    parser.add_argument(\"--hidden-dim\", type=int, default=256)\n",
    "    parser.add_argument(\"--depth\", type=int, default=6)\n",
    "    parser.add_argument(\"--heads\", type=int, default=8)\n",
    "    parser.add_argument(\"--dropout\", type=float, default=0.0)\n",
    "    parser.add_argument(\"--schedule\", choices=[\"linear\", \"cosine\"], default=\"cosine\")\n",
    "    parser.add_argument(\"--T\", type=int, default=1000, help=\"Number of diffusion steps\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    parser.add_argument(\"--steps\", type=int, default=1, help=\"Number of demo training steps to run\")\n",
    "    parser.add_argument(\"--workers\", type=int, default=4)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # --- Device & seed ---\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch.manual_seed(42)\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "\n",
    "    # --- Dataset / Loader ---\n",
    "    ds = PMTH5Dataset(h5_path=args.path)\n",
    "    loader = DataLoader(\n",
    "        ds,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=args.workers,\n",
    "        pin_memory=(device == \"cuda\"),\n",
    "        persistent_workers=(args.workers > 0),\n",
    "    )\n",
    "\n",
    "    # --- Model / Optim ---\n",
    "    model = PMTDiT(\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        depth=args.depth,\n",
    "        n_heads=args.heads,\n",
    "        cond_in_dim=6,\n",
    "        t_embed_dim=args.hidden_dim,      # often set equal to hidden_dim\n",
    "        cond_embed_dim=args.hidden_dim,   # dit-style\n",
    "        dropout=args.dropout,\n",
    "    ).to(device)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-2)\n",
    "\n",
    "    # --- Beta schedule ---\n",
    "    if args.schedule == \"linear\":\n",
    "        _, _, alpha_bars = make_beta_schedule_linear(args.T)\n",
    "    else:\n",
    "        _, _, alpha_bars = make_beta_schedule_cosine(args.T)\n",
    "    alpha_bars = alpha_bars.to(device)\n",
    "\n",
    "    # --- Run demo steps ---\n",
    "    it = iter(loader)\n",
    "    for step in range(args.steps):\n",
    "        try:\n",
    "            batch = next(it)\n",
    "        except StopIteration:\n",
    "            it = iter(loader)\n",
    "            batch = next(it)\n",
    "\n",
    "        loss = training_step_ddpm(model, batch, optim, device, alpha_bars, args.T)\n",
    "        print(f\"[step {step+1}/{args.steps}] loss: {loss:.6f}\")\n",
    "\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "from model import DiT3D\n",
    "import numexpr as ne\n",
    "ne.set_num_threads(64)     # 또는 더 작게: 16, 32 등\n",
    "model = DiT3D(\n",
    "    geom_csv=\"/home/work/GENESIS/GENESIS-pmj0324/GENESIS/genesis/utils/detector_geometry.csv\",  # (x,y,z) 5160개\n",
    "    L=5160, C=2,\n",
    "    d_model=64, depth=4, nhead=8,\n",
    "    te_dim=64, ff_mult=4,\n",
    "    num_freq=16, sigma=50.0,\n",
    "    cond_dim=0\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, torch as th\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class LinearSchedule:\n",
    "    def __init__(self, T=1000, beta_start=1e-4, beta_end=2e-2, device=\"cuda\"):\n",
    "        self.T = T\n",
    "        beta = th.linspace(beta_start, beta_end, T, device=device)\n",
    "        self.alpha = 1.0 - beta\n",
    "        self.alphabar = th.cumprod(self.alpha, dim=0)  # (T,)\n",
    "\n",
    "    def add_noise(self, x0, t, eps=None):\n",
    "        if eps is None: eps = th.randn_like(x0)\n",
    "        a_bar = self.alphabar[t].view(-1, 1, 1)       # (B,1,1)\n",
    "        x_t = th.sqrt(a_bar) * x0 + th.sqrt(1.0 - a_bar) * eps\n",
    "        return x_t, eps\n",
    "\n",
    "class H5InputSet(Dataset):\n",
    "    def __init__(self, h5_path, key=\"input\"):\n",
    "        self.f = h5py.File(h5_path, \"r\")\n",
    "        self.ds = self.f[key]            # (N,2,5160)\n",
    "        self.N  = self.ds.shape[0]\n",
    "    def __len__(self): return self.N\n",
    "    def __getitem__(self, i):\n",
    "        x = th.from_numpy(self.ds[i]).float()  # (2,5160)\n",
    "        x = x.transpose(0,1).contiguous()      # -> (5160,2)\n",
    "        return x\n",
    "    def close(self): self.f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = H5InputSet(\"/home/work/GENESIS/GENESIS-data/minje-version/22645_0730-noinf.h5\")\n",
    "dl = DataLoader(ds, batch_size=8, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "opt = th.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "sched = LinearSchedule(T=1000, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([743, 266,  79, 281, 515, 209, 242, 917], device='cuda:0')\n",
      "tensor([589,  87, 740, 467, 855, 630, 785, 771], device='cuda:0')\n",
      "tensor([550, 838, 897, 997, 316,  35, 796, 119], device='cuda:0')\n",
      "tensor([  1, 560, 183, 460, 864, 704, 123, 809], device='cuda:0')\n",
      "tensor([872, 610, 712, 106, 759, 760, 582, 120], device='cuda:0')\n",
      "tensor([220,  19, 484, 800, 309, 787, 909, 785], device='cuda:0')\n",
      "tensor([978, 491, 684,   6, 745, 721, 549, 686], device='cuda:0')\n",
      "tensor([ 16, 986, 516, 184, 553, 112, 677, 889], device='cuda:0')\n",
      "tensor([281, 618, 794, 275, 244, 468, 454, 151], device='cuda:0')\n",
      "tensor([517,  22, 872, 607, 305, 299, 876, 375], device='cuda:0')\n",
      "tensor([366, 961,  46,  15, 330, 277, 582, 397], device='cuda:0')\n",
      "tensor([823,  74, 606, 499, 449, 958,  28, 656], device='cuda:0')\n",
      "tensor([743, 930, 416, 788, 682, 302, 674, 462], device='cuda:0')\n",
      "tensor([236, 715, 269,  55, 407, 417, 487, 546], device='cuda:0')\n",
      "tensor([788, 996,  32, 152, 625, 723, 489, 912], device='cuda:0')\n",
      "tensor([485, 916, 163, 182, 857, 998, 486, 329], device='cuda:0')\n",
      "tensor([562, 877, 372, 353, 885,  98, 563, 342], device='cuda:0')\n",
      "tensor([326, 421,   2, 657,  10, 183,  21, 661], device='cuda:0')\n",
      "tensor([565, 192, 333,   6, 280,  74, 468, 793], device='cuda:0')\n",
      "tensor([254, 424,  90, 678, 476, 588, 838, 465], device='cuda:0')\n",
      "tensor([656, 714, 149, 875, 923, 430, 710, 203], device='cuda:0')\n",
      "tensor([133, 166, 408,   2, 801, 324, 268, 103], device='cuda:0')\n",
      "tensor([608, 319,  38,  49, 428, 533, 621, 573], device='cuda:0')\n",
      "tensor([523, 844, 525, 890, 515, 499, 756, 780], device='cuda:0')\n",
      "tensor([486, 473, 606, 894, 725, 447, 575, 643], device='cuda:0')\n",
      "tensor([293, 121, 356, 307, 907, 726, 624, 144], device='cuda:0')\n",
      "tensor([204,   5, 224, 941, 218, 796, 307,  81], device='cuda:0')\n",
      "tensor([135, 769, 544, 842, 909, 780, 401, 932], device='cuda:0')\n",
      "tensor([620, 930, 286, 584, 127, 511, 586, 675], device='cuda:0')\n",
      "tensor([ 78,  47, 958, 107,  42, 651, 998, 779], device='cuda:0')\n",
      "tensor([409, 421, 219, 848, 818, 520, 638, 961], device='cuda:0')\n",
      "tensor([778, 914, 518, 319, 407, 696, 787, 483], device='cuda:0')\n",
      "tensor([882, 759, 728, 599, 294, 809, 102, 774], device='cuda:0')\n",
      "tensor([126,   4,  25, 480, 393, 566, 551, 107], device='cuda:0')\n",
      "tensor([648, 892, 194, 139, 812, 799, 846,  10], device='cuda:0')\n",
      "tensor([233, 440, 450, 803, 259, 946, 875, 645], device='cuda:0')\n",
      "tensor([125, 362, 913, 281,  62, 446, 213, 357], device='cuda:0')\n",
      "tensor([ 40, 409, 949, 159, 847, 892, 264, 759], device='cuda:0')\n",
      "tensor([556, 459, 448, 515, 786, 808, 396, 449], device='cuda:0')\n",
      "tensor([ 42, 263, 942, 193, 471,  71, 984, 453], device='cuda:0')\n",
      "tensor([307, 489, 666, 753, 467, 703, 384, 286], device='cuda:0')\n",
      "tensor([620, 493,  68, 800, 793, 904, 849, 840], device='cuda:0')\n",
      "tensor([ 19, 861, 568, 928, 355, 671,   6, 876], device='cuda:0')\n",
      "tensor([ 38, 713, 950, 201, 475, 148, 403, 410], device='cuda:0')\n",
      "tensor([335, 702, 203, 590, 662, 354, 266, 935], device='cuda:0')\n",
      "tensor([649, 238, 822, 293, 767, 948, 776,  22], device='cuda:0')\n",
      "tensor([178, 597, 831, 168, 591, 122, 939, 220], device='cuda:0')\n",
      "tensor([602, 490,  42, 533, 824, 164,  72, 218], device='cuda:0')\n",
      "tensor([ 82, 822, 313, 248, 721, 347, 219,  51], device='cuda:0')\n",
      "tensor([643, 598, 346, 766, 879, 219, 532, 444], device='cuda:0')\n",
      "tensor([311, 146, 535, 819, 785, 829, 863, 798], device='cuda:0')\n",
      "tensor([622,  62,  24, 467, 298, 203, 219,  52], device='cuda:0')\n",
      "tensor([660,  79, 646, 416, 732, 754, 826, 488], device='cuda:0')\n",
      "tensor([582, 703, 607, 387,  98, 960, 674, 692], device='cuda:0')\n",
      "tensor([953, 332, 843, 913, 584, 477,  37, 667], device='cuda:0')\n",
      "tensor([679, 334, 884, 283, 203,  63, 965, 902], device='cuda:0')\n",
      "tensor([733, 761, 288, 406, 972, 382,  95, 888], device='cuda:0')\n",
      "tensor([789, 288, 193, 230, 897, 447, 899, 956], device='cuda:0')\n",
      "tensor([171, 952,  69,  42,  25, 224, 291, 793], device='cuda:0')\n",
      "tensor([173, 720, 720, 239,  53, 343, 451, 813], device='cuda:0')\n",
      "tensor([476, 200, 344, 794, 115, 670, 580, 251], device='cuda:0')\n",
      "tensor([199, 591, 790, 626, 503, 956, 281, 172], device='cuda:0')\n",
      "tensor([278, 697, 172, 896, 713, 387,  19, 398], device='cuda:0')\n",
      "tensor([197, 207, 193, 959, 498, 759, 296, 485], device='cuda:0')\n",
      "tensor([628, 771, 468, 557, 336,  83, 911, 446], device='cuda:0')\n",
      "tensor([996, 552,  35, 928, 655,  16, 451, 124], device='cuda:0')\n",
      "tensor([681, 560, 149, 959, 153, 119, 164, 893], device='cuda:0')\n",
      "tensor([131, 817, 469, 786, 583, 862,  90, 855], device='cuda:0')\n",
      "tensor([ 57, 775,  66, 233, 821, 236, 903,  17], device='cuda:0')\n",
      "tensor([997, 861, 984, 969, 328, 491, 824, 693], device='cuda:0')\n",
      "tensor([ 86, 123, 948, 229, 757, 215, 148, 779], device='cuda:0')\n",
      "tensor([885, 926, 548, 690, 467, 475, 336,  53], device='cuda:0')\n",
      "tensor([819, 146,  16, 609, 123, 150, 162, 387], device='cuda:0')\n",
      "tensor([334, 783, 177, 584, 877,  29,  64,   3], device='cuda:0')\n",
      "tensor([159, 962, 600, 908, 408, 819, 870, 400], device='cuda:0')\n",
      "tensor([397,   5,  27, 919, 506, 749, 154,  29], device='cuda:0')\n",
      "tensor([856,  33,  56, 996, 567,  23, 891, 592], device='cuda:0')\n",
      "tensor([885, 188, 774, 307, 909, 988, 823, 836], device='cuda:0')\n",
      "tensor([356, 955, 470, 729, 773, 199, 188, 105], device='cuda:0')\n",
      "tensor([ 79, 428, 638, 340, 481, 161, 364, 519], device='cuda:0')\n",
      "tensor([659, 290, 194, 366, 777, 639, 941, 539], device='cuda:0')\n",
      "tensor([740, 834, 618, 862, 847,  60, 545, 645], device='cuda:0')\n",
      "tensor([104, 575, 340, 421, 187, 385, 988, 153], device='cuda:0')\n",
      "tensor([969, 902, 923, 706, 291, 639, 750, 373], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      2\u001b[0m     total\u001b[38;5;241m=\u001b[39msteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x0 \u001b[38;5;129;01min\u001b[39;00m dl:\n\u001b[1;32m      4\u001b[0m         x0 \u001b[38;5;241m=\u001b[39m x0\u001b[38;5;241m.\u001b[39mcuda(non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)                   \u001b[38;5;66;03m# (B,5160,2)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m         B \u001b[38;5;241m=\u001b[39m x0\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pin_memory_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py:58\u001b[0m, in \u001b[0;36mpin_memory\u001b[0;34m(data, device)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpin_memory\u001b[39m(data, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    total=steps=0\n",
    "    for x0 in dl:\n",
    "        x0 = x0.cuda(non_blocking=True)                   # (B,5160,2)\n",
    "        B = x0.size(0)\n",
    "        t = th.randint(0, sched.T, (B,), device=\"cuda\")\n",
    "        print(t)\n",
    "        x_t, eps = sched.add_noise(x0, t)\n",
    "        eps_hat = model(x_t, t)\n",
    "        loss = ((eps_hat - eps) ** 2).mean()\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        th.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        total += loss.item(); steps += 1\n",
    "    print(f\"[Epoch {epoch+1}] loss={total/steps:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
