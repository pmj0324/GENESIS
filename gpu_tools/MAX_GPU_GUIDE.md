# GPU ìµœëŒ€ í™œìš© ê°€ì´ë“œ

GPUë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ê°€ì¥ ë¹ ë¥¸ í•™ìŠµì„ ì›í•˜ì‹œë‚˜ìš”?

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### max_gpu.yaml ì‚¬ìš© (ê¶Œì¥)

```bash
python scripts/train.py \
    --config configs/max_gpu.yaml \
    --data-path /home/work/GENESIS/GENESIS-data/22644_0921_time_shift.h5
```

**ì´ ì„¤ì •ì˜ íŠ¹ì§•:**
- âœ… ë°°ì¹˜ ì‚¬ì´ì¦ˆ: 2048 (ë§¤ìš° í¼)
- âœ… DataLoader workers: 12 (ë¹ ë¥¸ ë°ì´í„° ë¡œë”©)
- âœ… Mixed precision: True (í•„ìˆ˜)
- âœ… Learning rate: 0.0002 (í° ë°°ì¹˜ì— ë§ì¶¤)
- âœ… Warmup: 4% (ì•ˆì •ì  ì‹œì‘)

---

## âš™ï¸ GPU ìµœëŒ€ í™œìš© ì„¤ì •

### 1ï¸âƒ£ ë°°ì¹˜ ì‚¬ì´ì¦ˆ ìµœëŒ€í™”

**ìë™ ê°ì§€ (ì¶”ì²œ):**
```bash
python scripts/analysis/check_gpu_memory.py \
    --config configs/default.yaml \
    --auto-batch-size
```

ì¶œë ¥ì—ì„œ Maximum ê°’ì„ í™•ì¸í•˜ê³  ì‚¬ìš©:
```yaml
# configs/your_config.yaml
data:
  batch_size: 2048  # ë˜ëŠ” 4096
```

**ìˆ˜ë™ ì„¤ì •:**
- 80GB GPU: 2048, 4096
- 40GB GPU: 1024, 2048  
- 24GB GPU: 512, 1024
- 16GB GPU: 256, 512

### 2ï¸âƒ£ DataLoader ìµœì í™”

```yaml
data:
  num_workers: 12      # CPU ì½”ì–´ ìˆ˜ì— ë§ì¶° ì¡°ì • (ë³´í†µ 4-12)
  pin_memory: true     # GPU ì „ì†¡ ì†ë„ í–¥ìƒ (í•„ìˆ˜)
  batch_size: 2048     # í° ë°°ì¹˜
```

**num_workers ê¶Œì¥ê°’:**
- CPU ì½”ì–´ ë§ìŒ (32+): 12-16
- CPU ì½”ì–´ ë³´í†µ (16-32): 8-12
- CPU ì½”ì–´ ì ìŒ (<16): 4-8

### 3ï¸âƒ£ Mixed Precision í•„ìˆ˜

```yaml
training:
  use_amp: true  # ë°˜ë“œì‹œ í™œì„±í™”!
```

**íš¨ê³¼:**
- ë©”ëª¨ë¦¬: ~50% ì ˆì•½
- ì†ë„: ~2-3x ë¹ ë¦„
- ë°°ì¹˜: 2ë°° ë” í° ë°°ì¹˜ ê°€ëŠ¥

### 4ï¸âƒ£ Gradient Accumulation (ì„ íƒ)

ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•˜ë©´ì„œë„ í° effective batchë¥¼ ì›í•  ë•Œ:

```yaml
data:
  batch_size: 512        # ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©

training:
  gradient_accumulation_steps: 4  # Effective batch = 512 * 4 = 2048
```

### 5ï¸âƒ£ Learning Rate ì¡°ì •

í° ë°°ì¹˜ ì‚¬ìš© ì‹œ LRë„ ì¦ê°€:

```yaml
training:
  learning_rate: 0.0002  # batch 2048ì¼ ë•Œ
  # ê³µì‹: lr_new = lr_base * sqrt(batch_new / batch_base)
  # ì˜ˆ: 0.0001 * sqrt(2048 / 128) = 0.0001 * 4 = 0.0004
```

### 6ï¸âƒ£ Warmup ë¹„ìœ¨

```yaml
training:
  warmup_ratio: 0.04  # ì „ì²´ stepì˜ 4% (ê¶Œì¥)
  # ë˜ëŠ”
  warmup_ratio: 0.02  # 2% (ë¹ ë¥¸ ì‹œì‘)
  warmup_ratio: 0.06  # 6% (ì•ˆì •ì  ì‹œì‘)
```

### 7ï¸âƒ£ ë¡œê¹… ë¹ˆë„ ê°ì†Œ

```yaml
training:
  log_interval: 100   # 50 â†’ 100 (ëœ ìì£¼)
  save_interval: 1000 # ëœ ìì£¼ ì €ì¥
```

---

## ğŸ“Š ì„¤ì • ë¹„êµ

| í•­ëª© | Default | Max GPU | íš¨ê³¼ |
|------|---------|---------|------|
| Batch Size | 128 | 2048 | 16ë°° ë¹ ë¥¸ epoch |
| Num Workers | 4 | 12 | 3ë°° ë¹ ë¥¸ ë°ì´í„° ë¡œë”© |
| Mixed Precision | True | True | 2ë°° ë¹ ë¦„ |
| Learning Rate | 1e-4 | 2e-4 | í° ë°°ì¹˜ ë³´ìƒ |
| Warmup Ratio | 4% | 4% | ë™ì¼ |
| Log Interval | 50 | 100 | ì˜¤ë²„í—¤ë“œ ê°ì†Œ |

**ì˜ˆìƒ ì†ë„ í–¥ìƒ:**
- Epoch ì‹œê°„: 16ë°° ë‹¨ì¶• (ë°°ì¹˜ ì‚¬ì´ì¦ˆ)
- ë°ì´í„° ë¡œë”©: 2-3ë°° ë¹ ë¦„ (workers)
- ê³„ì‚°: 2ë°° ë¹ ë¦„ (mixed precision)
- **ì´ ì˜ˆìƒ: 20-30ë°° ë¹ ë¦„!**

---

## ğŸ¯ ì‹¤í–‰ ë°©ë²•

### ë°©ë²• 1: max_gpu.yaml ì‚¬ìš© (ê°€ì¥ ì‰¬ì›€)

```bash
python scripts/train.py \
    --config configs/max_gpu.yaml \
    --data-path /home/work/GENESIS/GENESIS-data/22644_0921_time_shift.h5
```

### ë°©ë²• 2: CLIë¡œ ì˜¤ë²„ë¼ì´ë“œ

```bash
python scripts/train.py \
    --config configs/default.yaml \
    --data-path /path/to/data.h5 \
    --batch-size 2048 \
    --lr 0.0002 \
    --use-amp
```

### ë°©ë²• 3: ê¸°ì¡´ config ìˆ˜ì •

```yaml
# configs/default.yaml
data:
  batch_size: 2048
  num_workers: 12

training:
  learning_rate: 0.0002
  use_amp: true
```

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### 1. OOM (Out of Memory) ë°œìƒ ì‹œ

```bash
# ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì ˆë°˜ìœ¼ë¡œ
batch_size: 1024  # 2048 â†’ 1024

# ë˜ëŠ” gradient accumulation ì‚¬ìš©
batch_size: 512
gradient_accumulation_steps: 4  # Effective: 2048
```

### 2. CPU ë³‘ëª© í™•ì¸

```bash
# í•™ìŠµ ì¤‘ ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ
htop  # ë˜ëŠ” top

# CPU ì‚¬ìš©ë¥ ì´ ë‚®ìœ¼ë©´ num_workers ì¦ê°€
num_workers: 16  # 12 â†’ 16
```

### 3. ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§

```bash
# GPU ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi

# ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ 50% ì´í•˜ë©´ ë°°ì¹˜ ì¦ê°€ ê°€ëŠ¥
```

---

## ğŸ“ˆ ì„±ëŠ¥ ì¸¡ì •

### ì˜ˆìƒ í•™ìŠµ ì‹œê°„ (178K samples, 80GB GPU)

| Config | Batch | Epoch ì‹œê°„ | 100 Epochs |
|--------|-------|-----------|------------|
| Default | 128 | ~15ë¶„ | ~25ì‹œê°„ |
| Optimized | 512 | ~4ë¶„ | ~7ì‹œê°„ |
| Max GPU | 2048 | ~1ë¶„ | ~2ì‹œê°„ |
| Extreme | 4096 | ~30ì´ˆ | ~1ì‹œê°„ |

**ìµœëŒ€ 25ë°° ì†ë„ í–¥ìƒ ê°€ëŠ¥!**

---

## ğŸ›ï¸ ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

í•™ìŠµ ì „ í™•ì¸:
- [ ] âœ… Mixed precision í™œì„±í™” (`use_amp: true`)
- [ ] âœ… í° ë°°ì¹˜ ì‚¬ì´ì¦ˆ (GPU ë©”ëª¨ë¦¬ì˜ 50-70%)
- [ ] âœ… ì¶©ë¶„í•œ num_workers (8-12)
- [ ] âœ… pin_memory í™œì„±í™”
- [ ] âœ… Learning rate ì¡°ì • (í° ë°°ì¹˜ìš©)
- [ ] âœ… Warmup ratio ì„¤ì • (4%)

í•™ìŠµ ì¤‘ ëª¨ë‹ˆí„°ë§:
- [ ] GPU ì‚¬ìš©ë¥  >90%
- [ ] CPU ë³‘ëª© ì—†ìŒ
- [ ] ë°ì´í„° ë¡œë”© ë¹ ë¦„
- [ ] Loss ì •ìƒ ê°ì†Œ

---

## ğŸ’¡ íŒ

### ê·¹í•œ ìµœì í™”

```yaml
data:
  batch_size: 4096  # ë˜ëŠ” 8192
  num_workers: 16
  pin_memory: true

training:
  learning_rate: 0.0004  # sqrt(4096/128) * 0.0001
  use_amp: true
  gradient_accumulation_steps: 1
  log_interval: 200  # ì˜¤ë²„í—¤ë“œ ìµœì†Œí™”
  
  # Early stopping ë¹„í™œì„±í™” (ìµœëŒ€ ì†ë„)
  early_stopping: false
```

### ë””ë²„ê·¸ í›„ max GPUë¡œ

```bash
# 1. ë””ë²„ê·¸ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
python scripts/train.py --config configs/debug.yaml --data-path /path/to/data.h5

# 2. ë¬¸ì œ ì—†ìœ¼ë©´ max GPUë¡œ
python scripts/train.py --config configs/max_gpu.yaml --data-path /path/to/data.h5
```

---

## ğŸ‰ ìµœì¢… ì¶”ì²œ

**80GB GPU (A100):**
```yaml
batch_size: 2048    # ë˜ëŠ” 4096
num_workers: 12
learning_rate: 0.0002
warmup_ratio: 0.04
```

**ì‹¤í–‰:**
```bash
python scripts/train.py \
    --config configs/max_gpu.yaml \
    --data-path /home/work/GENESIS/GENESIS-data/22644_0921_time_shift.h5
```

ìµœëŒ€ ì†ë„ë¡œ í•™ìŠµí•˜ì„¸ìš”! ğŸš€

