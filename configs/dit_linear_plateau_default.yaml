# Default configuration for GENESIS IceCube diffusion model
# ===========================================================
# This is the main configuration file with comprehensive options
# All paths are absolute for consistency across different environments

experiment_name: "dit_linear_plateau_default"
description: "Default DIT model with linear noise schedule and plateau LR scheduler"

# Model configuration
model:
  # Architecture type: "dit" (Diffusion Transformer), "c-dit" (Classifier-Attention DiT), "cnn", "hybrid"
  architecture: "dit"
  
  # Sequence length (number of PMTs)
  seq_len: 5160
  
  # Model dimensions
  hidden: 256          # Hidden dimension: 16, 64, 128, 256, 512, 1024
  depth: 4             # Number of transformer blocks: 2, 3, 4, 5, 6, 8, 12
  heads: 8             # Number of attention heads: 2, 4, 6, 8, 12, 16
  dropout: 0.1         # Dropout rate: 0.0, 0.05, 0.1, 0.15, 0.2
  
  # Fusion method: "SUM", "FiLM", "concat", "add"
  fusion: "FiLM"
  
  # Label configuration
  label_dim: 6         # [Energy, Zenith, Azimuth, X, Y, Z]
  t_embed_dim: 128     # Time embedding dimension: 32, 64, 128, 256
  
  # MLP configuration
  mlp_ratio: 4.0       # MLP expansion ratio: 2.0, 4.0, 6.0, 8.0
  
  # Normalization metadata (for denormalization during sampling)
  # Signal + Geometry: [charge, time, x, y, z]
  affine_offsets: [0.0, 0.0, -600.0, -550.0, -550.0]
  affine_scales: [200.0, 10.0, 1200.0, 1100.0, 1100.0]
  
  # Labels: [Energy, Zenith, Azimuth, X, Y, Z]
  label_offsets: [0.0, 0.0, 0.0, -600.0, -550.0, -550.0]
  label_scales: [100000000.0, 3.14159, 6.28318, 1200.0, 1100.0, 1100.0]
  
  # Time transformation: "ln" (natural log), "log10" (base-10 log), null (no transform)
  time_transform: "ln"

# Diffusion configuration
diffusion:
  # Number of diffusion timesteps: 100, 200, 500, 1000, 2000
  timesteps: 1000
  
  # Noise schedule parameters
  beta_start: 0.0001    # Start noise level: 0.0001, 0.0002, 0.0005
  beta_end: 0.024        # End noise level: 0.01, 0.02, 0.05, 0.1
  
  # Training objective: "eps" (predict noise), "x0" (predict clean data)
  objective: "eps"
  
  # Noise schedule: "linear", "cosine", "quadratic", "sigmoid"
  schedule: "linear"
  
  # Classifier-free guidance
  use_cfg: true         # Enable/disable CFG
  cfg_scale: 2.0        # CFG scale: 1.0, 1.5, 2.0, 3.0, 5.0
  cfg_dropout: 0.1      # CFG dropout rate: 0.0, 0.1, 0.2, 0.3

# Data configuration
data:
  # Data file path (absolute path for consistency)
  h5_path: "/home/work/GENESIS/GENESIS-pmj0324/GENESIS/GENESIS-data/22644_0921_time_shift.h5"
  
  # Data preprocessing
  replace_time_inf_with: 0.0    # Replace infinite time values with this value
  channel_first: true           # Data format: true (BCHW), false (BHWC)
  
  # Data loading
  batch_size: 512              # Batch size: 16, 32, 64, 128, 256, 512, 1024, 2048, 4096
  num_workers: 40              # Number of data loading workers: 0, 2, 4, 8, 12, 16, 20, 40
  pin_memory: true             # Pin memory for faster GPU transfer
  shuffle: true                # Shuffle training data
  
  # Data split ratios
  train_ratio: 0.8             # Training data ratio: 0.7, 0.8, 0.9
  val_ratio: 0.1               # Validation data ratio: 0.1, 0.15, 0.2
  test_ratio: 0.1              # Test data ratio: 0.1, 0.15, 0.2
  
  # Normalization (applied in Dataloader)
  time_transform: "ln"         # Time transformation: "ln", "log10", null
  affine_offsets: [0.0, 0.0, -600.0, -550.0, -550.0]  # [charge, time_ln, x, y, z]
  affine_scales: [200.0, 10.0, 1200.0, 1100.0, 1100.0]
  label_offsets: [0.0, 0.0, 0.0, -600.0, -550.0, -550.0]  # [Energy, Zenith, Azimuth, X, Y, Z]
  label_scales: [100000000.0, 3.14159, 6.28318, 1200.0, 1100.0, 1100.0]

# Training configuration
training:
  # Training duration
  num_epochs: 100              # Number of epochs: 10, 50, 100, 200, 500
  
  # Optimizer settings
  learning_rate: 0.0001        # Learning rate: 0.00001, 0.00005, 0.0001, 0.0002, 0.0005, 0.001
  weight_decay: 0.01           # Weight decay: 0.0, 0.001, 0.01, 0.1
  grad_clip_norm: 1.0          # Gradient clipping: 0.5, 1.0, 2.0, 5.0
  optimizer: "AdamW"           # Optimizer: "Adam", "AdamW", "SGD", "RMSprop"
  
  # Learning rate scheduler: "plateau", "cosine", "step", "linear", null
  scheduler: "plateau"
  warmup_steps: 1000           # Warmup steps: 0, 100, 500, 1000, 2000
  warmup_ratio: 0.04           # Warmup ratio: 0.01, 0.02, 0.04, 0.1

  # Plateau scheduler parameters
  plateau_patience: 2          # Patience: 1, 2, 3, 5, 10
  plateau_factor: 0.5          # Factor: 0.1, 0.3, 0.5, 0.7, 0.9
  plateau_mode: "min"          # Mode: "min", "max"
  plateau_threshold: 1e-6      # Threshold: 1e-8, 1e-6, 1e-4, 1e-3
  plateau_cooldown: 0          # Cooldown: 0, 1, 2, 5
  
  # Early stopping
  early_stopping: true         # Enable/disable early stopping
  early_stopping_patience: 5   # Patience: 3, 5, 10, 15, 20
  early_stopping_min_delta: 1e-4  # Minimum delta: 1e-6, 1e-5, 1e-4, 1e-3
  early_stopping_mode: "min"   # Mode: "min", "max"
  early_stopping_baseline: null # Baseline: null, 0.1, 0.5, 1.0
  early_stopping_restore_best: true  # Restore best weights
  early_stopping_verbose: true # Verbose output
  
  # Logging and checkpointing
  log_interval: 50             # Log interval: 10, 25, 50, 100, 200
  save_interval: 1000          # Save interval (not used with epoch-based saving)
  eval_interval: 1             # Evaluation interval: 1, 2, 5, 10
  
  # Output directories
  output_dir: "outputs"        # Output directory
  checkpoint_dir: "checkpoints" # Checkpoint directory
  log_dir: "logs"              # Log directory
  resume_from_checkpoint: null # Resume from checkpoint path
  
  # Performance settings
  use_amp: true                # Automatic Mixed Precision: true, false
  debug_mode: false            # Debug mode: true, false
  detect_anomaly: false        # Detect anomaly: true, false

# System settings
device: "auto"                 # Device: "auto", "cpu", "cuda", "cuda:0", "cuda:1"
seed: 42                       # Random seed: 0, 42, 123, 456, 789

# Logging and monitoring
use_wandb: false               # Use Weights & Biases: true, false
wandb_project: "icecube-diffusion"  # W&B project name
wandb_entity: null             # W&B entity/team name
