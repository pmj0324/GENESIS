# Small model configuration for faster training/testing

experiment_name: "icecube_diffusion_small"
description: "Small model configuration for faster training and testing"

# Model configuration - smaller architecture
model:
  seq_len: 5160
  hidden: 256
  depth: 4
  heads: 4
  dropout: 0.1
  fusion: "SUM"
  label_dim: 6
  t_embed_dim: 64
  mlp_ratio: 4.0
  affine_offsets: [0.0, 0.0, 0.0, 0.0, 0.0]
  affine_scales: [1.0, 100000.0, 1.0, 1.0, 1.0]

# Diffusion configuration - fewer timesteps
diffusion:
  timesteps: 100
  beta_start: 0.0001
  beta_end: 0.02
  objective: "eps"

# Data configuration
data:
  h5_path: "/home/work/GENESIS/GENESIS-data/22644_0921.h5"
  replace_time_inf_with: 0.0
  channel_first: true
  batch_size: 16
  num_workers: 4
  pin_memory: true
  shuffle: true
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1

# Training configuration - shorter training
training:
  num_epochs: 10
  learning_rate: 0.0002
  weight_decay: 0.01
  grad_clip_norm: 1.0
  optimizer: "AdamW"
  scheduler: null
  warmup_steps: 100
  
  # Early stopping
  early_stopping: false
  early_stopping_patience: 10
  early_stopping_min_delta: 1e-4
  early_stopping_mode: "min"
  early_stopping_baseline: null
  early_stopping_restore_best: true
  early_stopping_verbose: true
  
  log_interval: 10
  save_interval: 100
  eval_interval: 50
  output_dir: "./outputs"
  checkpoint_dir: "./checkpoints"
  log_dir: "./logs"
  resume_from_checkpoint: null
  use_amp: true
  debug_mode: false
  detect_anomaly: false

# System settings
device: "auto"
seed: 42

# Logging
use_wandb: false
wandb_project: "icecube-diffusion"
wandb_entity: null
