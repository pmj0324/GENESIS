# Noise Schedule Configurations

ì´ í´ë”ëŠ” ê° ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„ëŸ¬ë³„ë¡œ ìµœì í™”ëœ ëª¨ë¸ ì„¤ì •ì„ í¬í•¨í•©ë‹ˆë‹¤.

## ğŸ“ êµ¬ì¡°

```
configs/noise_schedules/
â”œâ”€â”€ README.md                    # ì´ íŒŒì¼
â”œâ”€â”€ linear.yaml                  # Linear Schedule (DDPM í‘œì¤€)
â”œâ”€â”€ cosine.yaml                  # Cosine Schedule (Improved DDPM)
â”œâ”€â”€ quadratic.yaml               # Quadratic Schedule
â””â”€â”€ sigmoid.yaml                 # Sigmoid Schedule
```

## ğŸ¯ ìŠ¤ì¼€ì¤„ëŸ¬ë³„ íŠ¹ì§•

### 1. Linear Schedule (DDPM í‘œì¤€)
- **íŒŒì¼**: `linear.yaml`
- **íŠ¹ì§•**: Î²_tê°€ ì„ í˜•ì ìœ¼ë¡œ ì¦ê°€
- **ì¥ì **: ì•ˆì •ì ì´ê³  ê²€ì¦ëœ ë°©ë²•
- **ë‹¨ì **: ì´ˆê¸° ë…¸ì´ì¦ˆê°€ ë„ˆë¬´ ì‘ì„ ìˆ˜ ìˆìŒ
- **ìµœì í™”**: 
  - Epochs: 300 (ë” ë§ì€ í›ˆë ¨ í•„ìš”)
  - Learning Rate: 0.0001 (ë³´ìˆ˜ì )
  - Batch Size: 32

### 2. Cosine Schedule (Improved DDPM)
- **íŒŒì¼**: `cosine.yaml`
- **íŠ¹ì§•**: Î²_tê°€ ì½”ì‚¬ì¸ í•¨ìˆ˜ë¡œ ì¦ê°€
- **ì¥ì **: ë” ë¶€ë“œëŸ¬ìš´ ë…¸ì´ì¦ˆ ì „í™˜, ë¹ ë¥¸ ìˆ˜ë ´
- **ë‹¨ì **: ë³µì¡í•œ ìˆ˜ì‹
- **ìµœì í™”**:
  - Epochs: 250 (ë¹ ë¥¸ ìˆ˜ë ´)
  - Learning Rate: 0.0002 (ì•½ê°„ ë†’ìŒ)
  - Batch Size: 32
  - Cosine s: 0.008

### 3. Quadratic Schedule
- **íŒŒì¼**: `quadratic.yaml`
- **íŠ¹ì§•**: Î²_tê°€ 2ì°¨ í•¨ìˆ˜ë¡œ ì¦ê°€
- **ì¥ì **: ì¤‘ê°„ ìˆ˜ì¤€ì˜ ë…¸ì´ì¦ˆ ì¦ê°€
- **ë‹¨ì **: ì´ˆê¸°/í›„ê¸° ê·¹ê°’ ë¬¸ì œ
- **ìµœì í™”**:
  - Epochs: 280 (ì¤‘ê°„ ìˆ˜ì¤€)
  - Learning Rate: 0.00015 (ì¤‘ê°„ ìˆ˜ì¤€)
  - Batch Size: 32

### 4. Sigmoid Schedule
- **íŒŒì¼**: `sigmoid.yaml`
- **íŠ¹ì§•**: Î²_tê°€ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¡œ ì¦ê°€
- **ì¥ì **: ë§¤ìš° ë¶€ë“œëŸ¬ìš´ ì „í™˜
- **ë‹¨ì **: ëŠë¦° ì´ˆê¸° ìˆ˜ë ´
- **ìµœì í™”**:
  - Epochs: 320 (ë” ë§ì€ í›ˆë ¨)
  - Learning Rate: 0.00008 (ë‚®ìŒ)
  - Batch Size: 32
  - Warmup Steps: 2500 (ê¸´ ì›Œë°ì—…)

## ğŸš€ ì‚¬ìš©ë²•

### ì§ì ‘ Python ì‹¤í–‰

```bash
# Linear Schedule
python scripts/train.py --config configs/noise_schedules/linear.yaml

# Cosine Schedule
python scripts/train.py --config configs/noise_schedules/cosine.yaml

# Quadratic Schedule
python scripts/train.py --config configs/noise_schedules/quadratic.yaml

# Sigmoid Schedule
python scripts/train.py --config configs/noise_schedules/sigmoid.yaml
```

### ëª¨ë“  ìŠ¤ì¼€ì¤„ëŸ¬ ë™ì‹œ í›ˆë ¨ (ë³‘ë ¬)

```bash
# ë°±ê·¸ë¼ìš´ë“œì—ì„œ ëª¨ë“  ìŠ¤ì¼€ì¤„ëŸ¬ í›ˆë ¨
python scripts/train.py --config configs/noise_schedules/linear.yaml &
python scripts/train.py --config configs/noise_schedules/cosine.yaml &
python scripts/train.py --config configs/noise_schedules/quadratic.yaml &
python scripts/train.py --config configs/noise_schedules/sigmoid.yaml &

# ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
wait
echo "ğŸ‰ ëª¨ë“  ìŠ¤ì¼€ì¤„ëŸ¬ í›ˆë ¨ ì™„ë£Œ!"
```

### ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„ ì‹œê°í™”

```bash
# ìŠ¤ì¼€ì¤„ ë¹„êµ ì‹œê°í™”
python -c "
from diffusion.noise_schedules import quick_schedule_comparison
quick_schedule_comparison(save_path='noise_schedules_comparison.png')
"

# ìƒì„¸ ì‹œê°í™” (ìƒ˜í”Œ ë°ì´í„° í¬í•¨)
python -c "
import torch
from diffusion.noise_schedules import plot_schedule_effects_on_sample

# ë”ë¯¸ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
sample_data = torch.randn(1, 2, 5160)
plot_schedule_effects_on_sample(sample_data, save_path='schedule_effects.png')
"
```

## ğŸ“Š ì¶œë ¥ êµ¬ì¡°

ê° ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” ë…ë¦½ì ì¸ ì¶œë ¥ í´ë”ë¥¼ ê°€ì§‘ë‹ˆë‹¤:

```
outputs/
â”œâ”€â”€ linear/              # Linear schedule ê²°ê³¼
â”œâ”€â”€ cosine/              # Cosine schedule ê²°ê³¼  
â”œâ”€â”€ quadratic/           # Quadratic schedule ê²°ê³¼
â””â”€â”€ sigmoid/             # Sigmoid schedule ê²°ê³¼

checkpoints/
â”œâ”€â”€ linear/              # Linear schedule ì²´í¬í¬ì¸íŠ¸
â”œâ”€â”€ cosine/              # Cosine schedule ì²´í¬í¬ì¸íŠ¸
â”œâ”€â”€ quadratic/           # Quadratic schedule ì²´í¬í¬ì¸íŠ¸
â””â”€â”€ sigmoid/             # Sigmoid schedule ì²´í¬í¬ì¸íŠ¸

logs/
â”œâ”€â”€ linear/              # Linear schedule ë¡œê·¸
â”œâ”€â”€ cosine/              # Cosine schedule ë¡œê·¸
â”œâ”€â”€ quadratic/           # Quadratic schedule ë¡œê·¸
â””â”€â”€ sigmoid/             # Sigmoid schedule ë¡œê·¸
```

## ğŸ”§ ì„¤ì • ì»¤ìŠ¤í„°ë§ˆì´ì§•

ê° `model.yaml` íŒŒì¼ì—ì„œ ë‹¤ìŒì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- **ëª¨ë¸ ì•„í‚¤í…ì²˜**: `model.hidden`, `model.depth`, `model.heads`
- **í›ˆë ¨ íŒŒë¼ë¯¸í„°**: `training.num_epochs`, `training.learning_rate`
- **ë°ì´í„° ì„¤ì •**: `data.batch_size`, `data.num_workers`
- **ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„**: `diffusion.beta_start`, `diffusion.beta_end`
- **ê°€ì´ë˜ìŠ¤**: `diffusion.cfg_scale`, `diffusion.cfg_dropout`

## ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ

í›ˆë ¨ ì™„ë£Œ í›„ ë‹¤ìŒ ë…¸íŠ¸ë¶ìœ¼ë¡œ ì„±ëŠ¥ì„ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- `testing/test_noise_schedules.ipynb`: ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„ ê¸°ë³¸ ë¹„êµ
- `testing/test_noise_schedule_stat_analysis.ipynb`: í†µê³„ì  ë¶„ì„
- `testing/test_diffusion.ipynb`: ì „ì²´ ë””í“¨ì „ í”„ë¡œì„¸ìŠ¤ ë¹„êµ

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **GPU ë©”ëª¨ë¦¬**: ê° ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” ë…ë¦½ì ìœ¼ë¡œ í›ˆë ¨ë˜ë¯€ë¡œ GPU ë©”ëª¨ë¦¬ë¥¼ ì¶©ë¶„íˆ í™•ë³´í•˜ì„¸ìš”
2. **ë””ìŠ¤í¬ ê³µê°„**: 4ê°œ ìŠ¤ì¼€ì¤„ëŸ¬ Ã— ì²´í¬í¬ì¸íŠ¸/ë¡œê·¸ = ìƒë‹¹í•œ ì €ì¥ ê³µê°„ í•„ìš”
3. **í›ˆë ¨ ì‹œê°„**: ìŠ¤ì¼€ì¤„ëŸ¬ë³„ë¡œ ìµœì í™”ëœ epoch ìˆ˜ê°€ ë‹¤ë¥´ë¯€ë¡œ í›ˆë ¨ ì‹œê°„ì´ ìƒì´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
4. **ì‹œë“œ ê³ ì •**: ëª¨ë“  ìŠ¤ì¼€ì¤„ëŸ¬ì—ì„œ `seed: 42`ë¡œ ê³ ì •ë˜ì–´ ìˆì–´ ê³µì •í•œ ë¹„êµê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤
