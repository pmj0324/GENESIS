{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Noise Schedule Statistical Analysis\n",
        "\n",
        "이 노트북은 각 노이즈 스케줄러에 대해 대량 데이터셋의 forward diffusion 통계적 분석을 수행합니다.\n",
        "\n",
        "## 🎯 목표\n",
        "- Linear, Cosine, Quadratic, Sigmoid 스케줄러별 대량 데이터 분석\n",
        "- 배치 단위 통계 (mean, std, percentiles)\n",
        "- Gaussian 수렴 테스트\n",
        "- 채널별 분석 (charge, time)\n",
        "- SNR 분석 (Signal-to-Noise Ratio)\n",
        "- 스케줄러별 성능 비교\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 환경 설정 및 라이브러리 임포트\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "import warnings\n",
        "from scipy import stats\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Git repository 루트 찾기\n",
        "def get_git_root():\n",
        "    try:\n",
        "        result = subprocess.run(['git', 'rev-parse', '--show-toplevel'], \n",
        "                              capture_output=True, text=True, check=True)\n",
        "        return result.stdout.strip()\n",
        "    except subprocess.CalledProcessError:\n",
        "        return str(Path.cwd().parent)\n",
        "\n",
        "git_root = get_git_root()\n",
        "project_root = Path(git_root)\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "print(f\"🔧 Git repository 루트: {git_root}\")\n",
        "print(f\"📁 프로젝트 루트: {project_root}\")\n",
        "\n",
        "# GENESIS 유틸리티 임포트\n",
        "from config import load_config_from_file\n",
        "from dataloader.pmt_dataloader import make_dataloader\n",
        "from diffusion.noise_schedules import (\n",
        "    linear_beta_schedule,\n",
        "    cosine_beta_schedule,\n",
        "    quadratic_beta_schedule,\n",
        "    sigmoid_beta_schedule,\n",
        "    compute_alpha_schedule\n",
        ")\n",
        "\n",
        "# 설정\n",
        "plt.rcParams['figure.figsize'] = (15, 10)\n",
        "plt.rcParams['font.size'] = 12\n",
        "print(\"✅ 라이브러리 임포트 완료!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 노이즈 스케줄러 설정 및 대량 데이터 준비\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 테스트 파라미터\n",
        "timesteps = 1000\n",
        "beta_start = 1e-4\n",
        "beta_end = 2e-2\n",
        "cosine_s = 0.008\n",
        "\n",
        "# 각 스케줄러별 Beta 값 생성\n",
        "schedules = {\n",
        "    'Linear': linear_beta_schedule(timesteps, beta_start, beta_end),\n",
        "    'Cosine': cosine_beta_schedule(timesteps, cosine_s),\n",
        "    'Quadratic': quadratic_beta_schedule(timesteps, beta_start, beta_end),\n",
        "    'Sigmoid': sigmoid_beta_schedule(timesteps, beta_start, beta_end)\n",
        "}\n",
        "\n",
        "# Alpha 값들 계산\n",
        "alpha_schedules = {}\n",
        "for name, betas in schedules.items():\n",
        "    alpha_schedules[name] = compute_alpha_schedule(betas)\n",
        "    print(f\"✅ {name} 스케줄러 Alpha 값 계산 완료\")\n",
        "\n",
        "# 데이터 로드\n",
        "config = load_config_from_file(str(project_root / 'configs' / 'default.yaml'))\n",
        "h5_path = str(project_root / config.data.h5_path)\n",
        "print(f\"\\n📁 H5 파일 경로: {h5_path}\")\n",
        "\n",
        "# 대량 데이터를 위한 데이터 로더\n",
        "batch_size = 64\n",
        "num_batches = 50  # 총 3200개 이벤트 분석\n",
        "\n",
        "dataloader = make_dataloader(\n",
        "    h5_path,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    replace_time_inf_with=config.data.replace_time_inf_with,\n",
        "    channel_first=config.data.channel_first\n",
        ")\n",
        "\n",
        "print(f\"📊 분석 설정:\")\n",
        "print(f\"  - 배치 크기: {batch_size}\")\n",
        "print(f\"  - 분석 배치 수: {num_batches}\")\n",
        "print(f\"  - 총 이벤트 수: {batch_size * num_batches}\")\n",
        "print(f\"  - 분석할 스케줄러: {list(schedules.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Forward Diffusion 통계 분석 함수 정의\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_forward_diffusion_batch(x_batch, timestep, alphas_dict):\n",
        "    \"\"\"Apply forward diffusion to a batch of signals.\"\"\"\n",
        "    sqrt_alphas_cumprod_t = alphas_dict['sqrt_alphas_cumprod'][timestep]\n",
        "    sqrt_one_minus_alphas_cumprod_t = alphas_dict['sqrt_one_minus_alphas_cumprod'][timestep]\n",
        "    \n",
        "    # Generate noise\n",
        "    noise = torch.randn_like(x_batch)\n",
        "    \n",
        "    # Forward diffusion: x_t = sqrt(ᾱ_t) * x_0 + sqrt(1-ᾱ_t) * ε\n",
        "    noisy_x = sqrt_alphas_cumprod_t * x_batch + sqrt_one_minus_alphas_cumprod_t * noise\n",
        "    \n",
        "    return noisy_x, noise\n",
        "\n",
        "def compute_batch_statistics(signals, channel_idx=None):\n",
        "    \"\"\"Compute comprehensive statistics for a batch of signals.\"\"\"\n",
        "    if channel_idx is not None:\n",
        "        signals = signals[:, channel_idx]\n",
        "    \n",
        "    # Basic statistics\n",
        "    mean = torch.mean(signals)\n",
        "    std = torch.std(signals)\n",
        "    min_val = torch.min(signals)\n",
        "    max_val = torch.max(signals)\n",
        "    \n",
        "    # Percentiles\n",
        "    percentiles = torch.quantile(signals, torch.tensor([0.1, 0.25, 0.5, 0.75, 0.9]))\n",
        "    \n",
        "    return {\n",
        "        'mean': mean.item(),\n",
        "        'std': std.item(),\n",
        "        'min': min_val.item(),\n",
        "        'max': max_val.item(),\n",
        "        'p10': percentiles[0].item(),\n",
        "        'p25': percentiles[1].item(),\n",
        "        'p50': percentiles[2].item(),\n",
        "        'p75': percentiles[3].item(),\n",
        "        'p90': percentiles[4].item()\n",
        "    }\n",
        "\n",
        "def gaussian_test(signals, channel_idx=None):\n",
        "    \"\"\"Test if signals follow Gaussian distribution.\"\"\"\n",
        "    if channel_idx is not None:\n",
        "        signals = signals[:, channel_idx]\n",
        "    \n",
        "    # Convert to numpy for scipy\n",
        "    signals_np = signals.cpu().numpy().flatten()\n",
        "    \n",
        "    # Kolmogorov-Smirnov test\n",
        "    ks_stat, ks_pvalue = stats.kstest(signals_np, 'norm', \n",
        "                                     args=(np.mean(signals_np), np.std(signals_np)))\n",
        "    \n",
        "    # Shapiro-Wilk test (for smaller samples)\n",
        "    if len(signals_np) <= 5000:\n",
        "        sw_stat, sw_pvalue = stats.shapiro(signals_np)\n",
        "    else:\n",
        "        # For large samples, use a subset\n",
        "        subset = np.random.choice(signals_np, 5000, replace=False)\n",
        "        sw_stat, sw_pvalue = stats.shapiro(subset)\n",
        "    \n",
        "    return {\n",
        "        'ks_statistic': ks_stat,\n",
        "        'ks_pvalue': ks_pvalue,\n",
        "        'ks_is_gaussian': ks_pvalue > 0.05,\n",
        "        'sw_statistic': sw_stat,\n",
        "        'sw_pvalue': sw_pvalue,\n",
        "        'sw_is_gaussian': sw_pvalue > 0.05\n",
        "    }\n",
        "\n",
        "def compute_snr(signals_original, signals_noisy, channel_idx=None):\n",
        "    \"\"\"Compute Signal-to-Noise Ratio.\"\"\"\n",
        "    if channel_idx is not None:\n",
        "        signals_original = signals_original[:, channel_idx]\n",
        "        signals_noisy = signals_noisy[:, channel_idx]\n",
        "    \n",
        "    # Signal power\n",
        "    signal_power = torch.mean(signals_original ** 2)\n",
        "    \n",
        "    # Noise power (estimated from difference)\n",
        "    noise = signals_noisy - signals_original\n",
        "    noise_power = torch.mean(noise ** 2)\n",
        "    \n",
        "    # SNR in dB\n",
        "    snr_db = 10 * torch.log10(signal_power / (noise_power + 1e-8))\n",
        "    \n",
        "    return snr_db.item()\n",
        "\n",
        "print(\"✅ 통계 분석 함수 정의 완료!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 대량 데이터 수집 및 각 스케줄러별 Forward Diffusion 통계 분석\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 대량 데이터 수집\n",
        "print(\"📦 대량 데이터 수집 중...\")\n",
        "all_signals = []\n",
        "\n",
        "for i, (x_sig_batch, _, _, _) in enumerate(dataloader):\n",
        "    if i >= num_batches:\n",
        "        break\n",
        "    \n",
        "    all_signals.append(x_sig_batch)\n",
        "    \n",
        "    if (i + 1) % 10 == 0:\n",
        "        print(f\"  📦 {i + 1}/{num_batches} 배치 수집 완료\")\n",
        "\n",
        "# 모든 데이터 결합\n",
        "all_signals = torch.cat(all_signals, dim=0)\n",
        "\n",
        "print(f\"\\n✅ 데이터 수집 완료!\")\n",
        "print(f\"📊 총 {all_signals.shape[0]}개 이벤트\")\n",
        "print(f\"📐 신호 shape: {all_signals.shape}\")\n",
        "\n",
        "# 원본 데이터 통계\n",
        "original_charge_stats = compute_batch_statistics(all_signals, channel_idx=0)\n",
        "original_time_stats = compute_batch_statistics(all_signals, channel_idx=1)\n",
        "\n",
        "print(f\"\\n📊 원본 데이터 통계:\")\n",
        "print(f\"  Charge - Mean: {original_charge_stats['mean']:.4f}, Std: {original_charge_stats['std']:.4f}\")\n",
        "print(f\"  Time   - Mean: {original_time_stats['mean']:.4f}, Std: {original_time_stats['std']:.4f}\")\n",
        "\n",
        "# 분석할 timestep들\n",
        "analysis_timesteps = [0, 100, 250, 500, 750, 999]\n",
        "print(f\"\\n🎯 분석 timesteps: {analysis_timesteps}\")\n",
        "\n",
        "# 각 스케줄러별 결과 저장\n",
        "scheduler_analysis_results = {}\n",
        "\n",
        "for scheduler_name, alphas in alpha_schedules.items():\n",
        "    print(f\"\\n🔄 {scheduler_name.upper()} 스케줄러 분석 중...\")\n",
        "    \n",
        "    scheduler_results = {}\n",
        "    \n",
        "    for t in analysis_timesteps:\n",
        "        print(f\"  📊 Timestep {t} 분석 중...\")\n",
        "        \n",
        "        # 배치별로 forward diffusion 적용\n",
        "        noisy_signals = []\n",
        "        batch_processing_size = 32  # 메모리 효율성을 위한 배치 크기\n",
        "        \n",
        "        for i in range(0, all_signals.shape[0], batch_processing_size):\n",
        "            batch = all_signals[i:i+batch_processing_size]\n",
        "            noisy_batch, noise_batch = apply_forward_diffusion_batch(batch, t, alphas)\n",
        "            noisy_signals.append(noisy_batch)\n",
        "        \n",
        "        # 모든 배치 결합\n",
        "        all_noisy = torch.cat(noisy_signals, dim=0)\n",
        "        \n",
        "        # 통계 계산\n",
        "        charge_stats = compute_batch_statistics(all_noisy, channel_idx=0)\n",
        "        time_stats = compute_batch_statistics(all_noisy, channel_idx=1)\n",
        "        \n",
        "        # Gaussian 테스트\n",
        "        charge_gaussian = gaussian_test(all_noisy, channel_idx=0)\n",
        "        time_gaussian = gaussian_test(all_noisy, channel_idx=1)\n",
        "        \n",
        "        # SNR 계산\n",
        "        charge_snr = compute_snr(all_signals, all_noisy, channel_idx=0)\n",
        "        time_snr = compute_snr(all_signals, all_noisy, channel_idx=1)\n",
        "        \n",
        "        # 결과 저장\n",
        "        scheduler_results[t] = {\n",
        "            'charge_stats': charge_stats,\n",
        "            'time_stats': time_stats,\n",
        "            'charge_gaussian': charge_gaussian,\n",
        "            'time_gaussian': time_gaussian,\n",
        "            'charge_snr': charge_snr,\n",
        "            'time_snr': time_snr,\n",
        "            'num_events': all_noisy.shape[0]\n",
        "        }\n",
        "        \n",
        "        print(f\"    ✅ Timestep {t} 완료 - {all_noisy.shape[0]}개 이벤트\")\n",
        "    \n",
        "    scheduler_analysis_results[scheduler_name] = scheduler_results\n",
        "    print(f\"✅ {scheduler_name.upper()} 분석 완료!\")\n",
        "\n",
        "print(f\"\\n🎉 모든 스케줄러 통계 분석 완료!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 통계 결과 시각화 및 상세 분석\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 통계 결과 시각화\n",
        "fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
        "\n",
        "colors = ['blue', 'red', 'green', 'orange']\n",
        "timestep_range = analysis_timesteps\n",
        "\n",
        "# Charge Mean\n",
        "ax = axes[0, 0]\n",
        "for i, (scheduler_name, results) in enumerate(scheduler_analysis_results.items()):\n",
        "    means = [results[t]['charge_stats']['mean'] for t in timestep_range]\n",
        "    ax.plot(timestep_range, means, 'o-', label=scheduler_name, \n",
        "           color=colors[i], linewidth=2, markersize=8)\n",
        "ax.set_title('Charge Mean vs Timestep', fontsize=14)\n",
        "ax.set_xlabel('Timestep')\n",
        "ax.set_ylabel('Mean Charge')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Charge Std\n",
        "ax = axes[0, 1]\n",
        "for i, (scheduler_name, results) in enumerate(scheduler_analysis_results.items()):\n",
        "    stds = [results[t]['charge_stats']['std'] for t in timestep_range]\n",
        "    ax.plot(timestep_range, stds, 'o-', label=scheduler_name, \n",
        "           color=colors[i], linewidth=2, markersize=8)\n",
        "ax.set_title('Charge Std vs Timestep', fontsize=14)\n",
        "ax.set_xlabel('Timestep')\n",
        "ax.set_ylabel('Std Charge')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Time Mean\n",
        "ax = axes[0, 2]\n",
        "for i, (scheduler_name, results) in enumerate(scheduler_analysis_results.items()):\n",
        "    means = [results[t]['time_stats']['mean'] for t in timestep_range]\n",
        "    ax.plot(timestep_range, means, 'o-', label=scheduler_name, \n",
        "           color=colors[i], linewidth=2, markersize=8)\n",
        "ax.set_title('Time Mean vs Timestep', fontsize=14)\n",
        "ax.set_xlabel('Timestep')\n",
        "ax.set_ylabel('Mean Time')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Time Std\n",
        "ax = axes[1, 0]\n",
        "for i, (scheduler_name, results) in enumerate(scheduler_analysis_results.items()):\n",
        "    stds = [results[t]['time_stats']['std'] for t in timestep_range]\n",
        "    ax.plot(timestep_range, stds, 'o-', label=scheduler_name, \n",
        "           color=colors[i], linewidth=2, markersize=8)\n",
        "ax.set_title('Time Std vs Timestep', fontsize=14)\n",
        "ax.set_xlabel('Timestep')\n",
        "ax.set_ylabel('Std Time')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Charge SNR\n",
        "ax = axes[1, 1]\n",
        "for i, (scheduler_name, results) in enumerate(scheduler_analysis_results.items()):\n",
        "    snrs = [results[t]['charge_snr'] for t in timestep_range]\n",
        "    ax.plot(timestep_range, snrs, 'o-', label=scheduler_name, \n",
        "           color=colors[i], linewidth=2, markersize=8)\n",
        "ax.set_title('Charge SNR vs Timestep', fontsize=14)\n",
        "ax.set_xlabel('Timestep')\n",
        "ax.set_ylabel('SNR (dB)')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Time SNR\n",
        "ax = axes[1, 2]\n",
        "for i, (scheduler_name, results) in enumerate(scheduler_analysis_results.items()):\n",
        "    snrs = [results[t]['time_snr'] for t in timestep_range]\n",
        "    ax.plot(timestep_range, snrs, 'o-', label=scheduler_name, \n",
        "           color=colors[i], linewidth=2, markersize=8)\n",
        "ax.set_title('Time SNR vs Timestep', fontsize=14)\n",
        "ax.set_xlabel('Timestep')\n",
        "ax.set_ylabel('SNR (dB)')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(str(project_root / 'testing' / 'noise_schedule_stat_analysis.png'), \n",
        "            dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ 통계 분석 시각화 완료!\")\n",
        "\n",
        "# 상세 결과 요약\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"📊 NOISE SCHEDULE STATISTICAL ANALYSIS RESULTS\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "print(f\"\\n🎯 분석 요약:\")\n",
        "print(f\"  - 총 이벤트 수: {all_signals.shape[0]:,}\")\n",
        "print(f\"  - 분석 timesteps: {analysis_timesteps}\")\n",
        "print(f\"  - 스케줄러 수: {len(scheduler_analysis_results)}\")\n",
        "\n",
        "for scheduler_name, results in scheduler_analysis_results.items():\n",
        "    print(f\"\\n🔸 {scheduler_name.upper()} SCHEDULE:\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    for t in analysis_timesteps:\n",
        "        result = results[t]\n",
        "        print(f\"\\n  📊 Timestep {t}:\")\n",
        "        \n",
        "        # Charge 통계\n",
        "        charge_stats = result['charge_stats']\n",
        "        print(f\"    Charge - Mean: {charge_stats['mean']:.4f}, Std: {charge_stats['std']:.4f}\")\n",
        "        print(f\"             Range: [{charge_stats['min']:.4f}, {charge_stats['max']:.4f}]\")\n",
        "        \n",
        "        # Time 통계\n",
        "        time_stats = result['time_stats']\n",
        "        print(f\"    Time   - Mean: {time_stats['mean']:.4f}, Std: {time_stats['std']:.4f}\")\n",
        "        print(f\"             Range: [{time_stats['min']:.4f}, {time_stats['max']:.4f}]\")\n",
        "        \n",
        "        # SNR\n",
        "        print(f\"    SNR    - Charge: {result['charge_snr']:.2f} dB, Time: {result['time_snr']:.2f} dB\")\n",
        "        \n",
        "        # Gaussian 테스트\n",
        "        charge_ks_gaussian = result['charge_gaussian']['ks_is_gaussian']\n",
        "        time_ks_gaussian = result['time_gaussian']['ks_is_gaussian']\n",
        "        charge_sw_gaussian = result['charge_gaussian']['sw_is_gaussian']\n",
        "        time_sw_gaussian = result['time_gaussian']['sw_is_gaussian']\n",
        "        \n",
        "        print(f\"    Gaussian - Charge KS: {'✅' if charge_ks_gaussian else '❌'}, SW: {'✅' if charge_sw_gaussian else '❌'}\")\n",
        "        print(f\"               Time KS: {'✅' if time_ks_gaussian else '❌'}, SW: {'✅' if time_sw_gaussian else '❌'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"✅ 모든 분석 완료! 결과 이미지가 testing/ 폴더에 저장되었습니다.\")\n",
        "print(\"📁 저장된 파일:\")\n",
        "print(\"  - noise_schedule_stat_analysis.png\")\n",
        "print(\"=\"*100)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
