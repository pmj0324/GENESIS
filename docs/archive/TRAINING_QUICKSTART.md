# ğŸš€ Training Quick Start Guide

ë””í´íŠ¸ ì„¤ì •ìœ¼ë¡œ ë°”ë¡œ í•™ìŠµì„ ì‹œì‘í•˜ëŠ” ê°€ì´ë“œì…ë‹ˆë‹¤.

## âš™ï¸ í˜„ì¬ ì„¤ì • (Default Config)

```yaml
# configs/default.yaml

Model:
  - Architecture: DiT (Diffusion Transformer)
  - Hidden: 16
  - Depth: 3
  - Heads: 8
  - Fusion: SUM

Normalization:
  - Charge: x / 200 â†’ [0, ~1.125]
  - Time: ln(x) / 10 â†’ [~0.46, ~1.18]
  - Position: x / 500 â†’ [-1, 1]
  
Training:
  - Epochs: 100
  - Batch size: 128
  - Learning rate: 1e-4
  - Scheduler: Cosine Annealing
  - Early stopping: True (patience=4)
  - Mixed precision: True

Diffusion:
  - Timesteps: 1000
  - Beta: [0.0001, 0.02]
  - Objective: eps (noise prediction)
  - Schedule: linear
```

## ğŸ¯ ì‹¤í–‰ ëª…ë ¹ì–´

### 1. ê¸°ë³¸ í•™ìŠµ (Default Config)

```bash
python scripts/train.py \
    --config configs/default.yaml \
    --data-path /home/work/GENESIS/GENESIS-data/22644_0921_time_shift.h5
```

### 2. ë””ë²„ê·¸ ëª¨ë“œ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)

```bash
python scripts/train.py \
    --config configs/debug.yaml \
    --data-path /home/work/GENESIS/GENESIS-data/22644_0921_time_shift.h5
```

### 3. Custom ì„¤ì •ìœ¼ë¡œ í•™ìŠµ

```bash
python scripts/train.py \
    --config configs/default.yaml \
    --data-path /home/work/GENESIS/GENESIS-data/22644_0921_time_shift.h5 \
    --epochs 200 \
    --batch-size 64 \
    --lr 2e-4 \
    --experiment-name "my_experiment"
```

### 4. ë‹¤ë¥¸ ì•„í‚¤í…ì²˜ ì‹œë„

```bash
# CNN (faster)
python scripts/train.py \
    --config configs/cnn.yaml \
    --data-path /home/work/GENESIS/GENESIS-data/22644_0921_time_shift.h5

# Hybrid (CNN + Transformer)
python scripts/train.py \
    --config configs/hybrid.yaml \
    --data-path /home/work/GENESIS/GENESIS-data/22644_0921_time_shift.h5
```

### 5. ë‹¤ë¥¸ Scheduler ì‹œë„

```bash
# Cosine Annealing (default)
python scripts/train.py \
    --config configs/cosine_annealing.yaml \
    --data-path /home/work/GENESIS/GENESIS-data/22644_0921_time_shift.h5

# ReduceLROnPlateau
python scripts/train.py \
    --config configs/plateau.yaml \
    --data-path /home/work/GENESIS/GENESIS-data/22644_0921_time_shift.h5
```

## ğŸ“Š í•™ìŠµ ì¤‘ ëª¨ë‹ˆí„°ë§

### TensorBoard ì‚¬ìš©

```bash
# í•™ìŠµì´ ì‹œì‘ëœ í›„, ìƒˆ í„°ë¯¸ë„ì—ì„œ:
tensorboard --logdir logs/
```

ê·¸ë¦¬ê³  ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:6006` ì—´ê¸°

### ì²´í¬í¬ì¸íŠ¸ í™•ì¸

```bash
# ì²´í¬í¬ì¸íŠ¸ í™•ì¸
ls -lh checkpoints/

# ìµœì‹  ì²´í¬í¬ì¸íŠ¸
ls -lt checkpoints/ | head -5
```

## ğŸ¯ Early Stopping ì„¤ì •

í˜„ì¬ ì„¤ì • (patience=4):
- 4 epoch ë™ì•ˆ lossê°€ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ í•™ìŠµ ì¤‘ë‹¨
- ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìë™ ë³µì›
- ìµœê³  ëª¨ë¸ì€ `checkpoints/best_model.pth`ë¡œ ì €ì¥

ì›í•˜ëŠ” ê²½ìš° CLIì—ì„œ ë³€ê²½ ê°€ëŠ¥:
```bash
python scripts/train.py \
    --config configs/default.yaml \
    --data-path /path/to/data.h5 \
    --early-stopping-patience 10  # patienceë¥¼ 10ìœ¼ë¡œ ë³€ê²½
```

## ğŸ“ˆ í•™ìŠµ í›„ ìƒ˜í”Œ ìƒì„±

```bash
# ìµœê³  ëª¨ë¸ë¡œ ìƒ˜í”Œ ìƒì„±
python scripts/sample.py \
    --config configs/default.yaml \
    --checkpoint checkpoints/best_model.pth \
    --num-samples 100 \
    --visualize \
    --output-dir generated_events
```

## ğŸ” Diffusion ê³¼ì • í™•ì¸

### í•™ìŠµ ì „: Diffusion ê³¼ì • ì‹œê°í™”

```bash
python scripts/visualization/visualize_diffusion.py \
    --config configs/default.yaml \
    --num-samples 4
```

### í•™ìŠµ ì „: Forward Diffusion ë¶„ì„

```bash
python scripts/analysis/analyze_diffusion.py \
    --config configs/default.yaml \
    --data-path /home/work/GENESIS/GENESIS-data/22644_0921_time_shift.h5 \
    --visualize-schedule \
    --compare-schedules \
    --output-dir diffusion_analysis
```

## ğŸ’¡ ì¶”ì²œ ì›Œí¬í”Œë¡œìš°

### Step 1: í™˜ê²½ í™•ì¸
```bash
python scripts/setup/getting_started.py
```

### Step 2: Diffusion ë¶„ì„ (ì„ íƒ)
```bash
python scripts/analysis/analyze_diffusion.py \
    --config configs/default.yaml \
    --data-path /path/to/data.h5 \
    --visualize-schedule
```

### Step 3: ë””ë²„ê·¸ ëª¨ë“œë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
```bash
python scripts/train.py \
    --config configs/debug.yaml \
    --data-path /path/to/data.h5
```

### Step 4: ë³¸ê²© í•™ìŠµ
```bash
python scripts/train.py \
    --config configs/default.yaml \
    --data-path /path/to/data.h5
```

### Step 5: ìƒ˜í”Œ ìƒì„± ë° í‰ê°€
```bash
python scripts/sample.py \
    --checkpoint checkpoints/best_model.pth \
    --num-samples 100 \
    --visualize
```

## ğŸ›ï¸ ì£¼ìš” ì„¤ì • ë³€ê²½

### Learning Rate ì¡°ì •
```bash
--lr 2e-4  # ë” ë¹ ë¥¸ í•™ìŠµ
--lr 5e-5  # ë” ì•ˆì •ì ì¸ í•™ìŠµ
```

### Batch Size ì¡°ì • (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼)
```bash
--batch-size 64   # ë” ì‘ì€ batch (ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ)
--batch-size 256  # ë” í° batch (ì¶©ë¶„í•œ ë©”ëª¨ë¦¬)
```

### Early Stopping ì¡°ì •
```bash
--early-stopping-patience 10  # ë” ì˜¤ë˜ ê¸°ë‹¤ë¦¼
--early-stopping-patience 2   # ë¹¨ë¦¬ ì¤‘ë‹¨
```

## ğŸ“ ì˜ˆìƒ í•™ìŠµ ì‹œê°„

**Default Config (hidden=16, depth=3):**
- GPU: NVIDIA A100 80GB
- Batch size: 128
- Dataset: ~178K samples
- ì˜ˆìƒ ì‹œê°„: ~1-2ì‹œê°„ (100 epochs)

**Debug Config:**
- Epochs: 2
- ì˜ˆìƒ ì‹œê°„: ~1-2ë¶„

## ğŸ‰ Ready to Train!

ì´ì œ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ë°”ë¡œ í•™ìŠµì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
python scripts/train.py \
    --config configs/default.yaml \
    --data-path /home/work/GENESIS/GENESIS-data/22644_0921_time_shift.h5
```

Happy Training! ğŸš€

